{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\"><b>Регрессия, классификация и кластеризация </b> в <span style=\"font-weight:bold; color:green\">Spark</span></div><hr>\n",
    "<div style=\"text-align:right;\">Папулин С.Ю. <span style=\"font-style: italic;font-weight: bold;\">(papulin_bmstu@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"0\"></a>\n",
    "<div><span style=\"font-size:14pt; font-weight:bold\">Содержание</span>\n",
    "    <ol>\n",
    "        <li><a href=\"#1\">Регрессия</a>\n",
    "            <ol style = \"list-style-type:lower-alpha\">\n",
    "                <li><a href=\"#1a\">Линейная регрессия</a></li>\n",
    "                <li><a href=\"#1b\">Решающее дерево</a></li>\n",
    "                <li><a href=\"#1c\">Полимиальная регрессия</a></li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><a href=\"#2\">Классификация</a>\n",
    "            <ol style = \"list-style-type:lower-alpha\">\n",
    "                <li><a href=\"#2a\">Логистическая регрессия</a></li>\n",
    "                <li><a href=\"#2b\">Решающее дерево</a></li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><a href=\"#3\">Кластеризация</a>\n",
    "            <ol style = \"list-style-type:lower-alpha\">\n",
    "                <li><a href=\"#3a\">K-Mean</a></li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><a href=\"#4\">Источники</a>\n",
    "        </li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>[ОПЦИОНАЛЬНО] <b>Настройка среды</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"]=\"/usr/lib/spark\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/opt/anaconda3/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/opt/anaconda3/bin/python\"\n",
    "\n",
    "spark_home = os.environ.get(\"SPARK_HOME\")\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python\"))\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python/lib/py4j-0.10.7-src.zip\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключение модуля **pyspark**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Запуск Spark Context</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск на YARN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf = pyspark.SparkConf() \\\n",
    "#         .setAppName(\"mllibRDDApp\") \\\n",
    "#         .setMaster(\"yarn\") \\\n",
    "#         .set(\"spark.submit.deployMode\", \"client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Локальный запуск:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf() \\\n",
    "        .setAppName(\"basicOperationsRDDApp\") \\\n",
    "        .set(\"spark.executor.memory\", \"1g\") \\\n",
    "        .set(\"spark.executor.core\", \"2\") \\\n",
    "        .setMaster(\"local[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Подключение дополнительных библиотек</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "clrMap = ListedColormap([\"blue\", \"red\", \"green\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">1. Регрессия</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"1a\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            a. Линейная регрессия\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#1\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#1b\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LinearRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Загрузите данные из файла</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>[ЕСЛИ НЕОБХОДИМО] Скопируйте локальный датасет в HDFS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal data/ml-basics-data/regression_demo.csv data/ml-basics-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDFS\n",
    "file_path_reg = \"hdfs:///YOUR_PATH/regression_demo.csv\"\n",
    "\n",
    "# Local file\n",
    "file_path_reg = \"file:///YOUR_PATH/regression_demo.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rdd = sc.textFile(file_path_reg)\n",
    "data_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Создайте RDD без первой строки (она содержит заголовок)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabeledPoint(line):\n",
    "    if line[0] != \"X\":\n",
    "        els = [float(el) for el in line.split(\",\")] \n",
    "        return LabeledPoint(els[1], els[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xy_rdd = data_rdd \\\n",
    "    .map(getLabeledPoint) \\\n",
    "    .filter(lambda x: x != None)\n",
    "\n",
    "data_xy_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Отобразите исходных данных</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data_xy_rdd.takeSample(withReplacement=False, num=80, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in data_sample:\n",
    "    plt.plot(el.features[0], el.label, \"bo\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Initial Data\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Сформируйте обучающее и тестовое подмножества</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rdd, test_rdd = data_xy_rdd.randomSplit([0.7, 0.3], seed=123)\n",
    "train_rdd.persist(), test_rdd.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Отобразите количество элементов в каждом из подмножеств</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rdd.count(), test_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Обучите модель линейной регрессии на обучающем подмножестве</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://spark.apache.org/docs/2.2.0/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionWithSGD\">LinearRegressionWithSGD</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linReg = LinearRegressionWithSGD.train(train_rdd, intercept=True)\n",
    "model_linReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверьте результат обучения на тестовом подмножестве с использованием MSE</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairsTruePred_rdd = test_rdd.map(lambda x: (x.label, model_linReg.predict(x.features)))\n",
    "pairsTruePred_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = pairsTruePred_rdd \\\n",
    "    .map(lambda x: (x[0]-x[1])**2) \\\n",
    "    .reduce(lambda x1, x2: x1+x2) / test_rdd \\\n",
    "    .count()\n",
    "\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Постройте итоговые графики</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.arange(0, 5, 0.01)[np.newaxis,:]\n",
    "\n",
    "# Предсказанные моделью значения\n",
    "y_pred = model_linReg.predict(xx)\n",
    "\n",
    "# График \n",
    "plt.figure(1)\n",
    "plt.subplot(1,1,1)\n",
    "\n",
    "plt.plot(xx[0,:], y_pred, c=\"black\", label=\"\", linewidth=2)\n",
    "plt.title(\"Initial Data\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "for el in data_sample:\n",
    "    plt.plot(el.features[0], el.label, \"bo\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"1b\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            b. Решающее дерево\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#1a\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#1c\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Постройте решающее дерево для задачи регрессии с использованием данных из предыдущего примера</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://spark.apache.org/docs/2.2.0/api/python/pyspark.mllib.html#pyspark.mllib.tree.DecisionTree\">DecisionTree</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_decTree = DecisionTree.trainRegressor(train_rdd, \n",
    "                                            impurity=\"variance\", \n",
    "                                            maxDepth=2, \n",
    "                                            categoricalFeaturesInfo={})\n",
    "model_decTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверьте на тестовом подмножестве</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rdd = model_decTree.predict(test_rdd.map(lambda x: x.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairsTruePred_rdd = test_rdd \\\n",
    "    .map(lambda x: x.label) \\\n",
    "    .zip(test_pred_rdd)\n",
    "\n",
    "pairsTruePred_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = pairsTruePred_rdd \\\n",
    "    .map(lambda x: (x[0]-x[1])**2) \\\n",
    "    .reduce(lambda x1, x2: x1+x2) / test_rdd.count()\n",
    "\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Постройте итоговые графики</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.arange(0, 5, 0.01)\n",
    "\n",
    "# Предсказанные моделью значения\n",
    "y_pred = [model_decTree.predict([el]) for el in xx]\n",
    "\n",
    "# График\n",
    "plt.figure(1)\n",
    "plt.subplot(1,1,1)\n",
    "plt.plot(xx, y_pred, c=\"black\", label=\"\", linewidth=2)\n",
    "plt.title(\"Initial Data\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "for el in data_sample:\n",
    "    plt.plot(el.features[0], el.label, \"bo\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"1c\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            c. Полимиальная регрессия\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#1b\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Преобразуйте исходные данные из предыдущих примеров в массив степеней Х</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Степень полинома\n",
    "POLY_DEGREE = 10\n",
    "\n",
    "\n",
    "# Преобразование х в массив х^n, где 0 <= n <= deg\n",
    "def transform_1d_to_polynomial_features(item, degree=POLY_DEGREE):\n",
    "    return [item.features[0]**i for i in range(0, degree+1)]\n",
    "\n",
    "\n",
    "# RDD транcформация \n",
    "train_features_poly_rdd = train_rdd.map(transform_1d_to_polynomial_features)\n",
    "test_features_poly_rdd = test_rdd.map(transform_1d_to_polynomial_features)\n",
    "\n",
    "# Вывод первых двух элементов RDD для обучающих данных\n",
    "train_features_poly_rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общий подход для $p$ признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLY_DEGREE = 10\n",
    "\n",
    "def transform_to_polynomial_features(items):\n",
    "    \n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    \n",
    "    pf = PolynomialFeatures(degree=POLY_DEGREE)\n",
    "    yield pf.fit_transform([next(items).features]).flatten()\n",
    "    \n",
    "    for item in items:\n",
    "        yield np.array(pf.transform([item.features])).flatten()\n",
    "        \n",
    "train_features_poly_rdd = train_rdd.mapPartitions(transform_to_polynomial_features)\n",
    "test_features_poly_rdd = test_rdd.mapPartitions(transform_to_polynomial_features)\n",
    "\n",
    "train_features_poly_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Нормализуйте каждый полученный признак к стандартному нормальному распределнию - стандартизация</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель стандартизации\n",
    "stand = StandardScaler(withMean=True, withStd=True)\n",
    "\n",
    "# Вычисление математического ожидания и стандартного отклонения\n",
    "scaler = stand.fit(train_features_poly_rdd)\n",
    "\n",
    "# Стандартизация train_features_poly_rdd и test_features_poly_norm_rdd\n",
    "train_features_poly_norm_rdd = scaler.transform(train_features_poly_rdd)\n",
    "test_features_poly_norm_rdd = scaler.transform(test_features_poly_rdd)\n",
    "\n",
    "# Вывод первых пяти элементов RDD для обучающих данных\n",
    "train_features_poly_norm_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Создайте новые обучающий и тестовый наборы с учетом проведенных преобразований с Х</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формирование RDD с действиетельными значениями\n",
    "train_labels_rdd = train_rdd.map(lambda x: x.label)\n",
    "test_labels_rdd = test_rdd.map(lambda x: x.label)\n",
    "\n",
    "# Объединение train_labels_rdd и train_features_poly_norm_rdd и поместите значения в LabeledPoint\n",
    "train_poly_rdd = train_labels_rdd \\\n",
    "    .zip(train_features_poly_norm_rdd) \\\n",
    "    .map(lambda x: LabeledPoint(x[0], x[1]))\n",
    "\n",
    "# Объединение test_labels_rdd и test_features_poly_norm_rdd и поместите значения в LabeledPoint\n",
    "test_poly_rdd = test_labels_rdd \\\n",
    "    .zip(test_features_poly_norm_rdd) \\\n",
    "    .map(lambda x: LabeledPoint(x[0], x[1]))\n",
    "\n",
    "# Вывод первых пяти элементов RDD для обучающих данных\n",
    "train_poly_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Произведите обучение модели линейного регрессии</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://spark.apache.org/docs/2.2.0/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionWithSGD\">LinearRegressionWithSGD</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linReg = LinearRegressionWithSGD.train(train_poly_rdd, \n",
    "                                             intercept=True, \n",
    "                                             regParam=10e-4, \n",
    "                                             regType=\"l2\", \n",
    "                                             iterations=300)\n",
    "model_linReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверьте на тестовом подмножестве</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = test_poly_rdd \\\n",
    "    .map(lambda x: (x.label, model_linReg.predict(x.features))) \\\n",
    "    .map(lambda x: (x[0]-x[1])**2) \\\n",
    "    .reduce(lambda x1, x2: x1+x2) / test_rdd.count()\n",
    "\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Постройте итоговые графики</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_1d_to_polynomial_features_(x, degree=POLY_DEGREE):\n",
    "    return [x**i for i in range(0, degree+1)]\n",
    "\n",
    "xx = np.arange(0, 5, 0.01)[np.newaxis,:]\n",
    "\n",
    "# Предсказанные моделью значения\n",
    "xx_powers_rdd = sc.parallelize(list(map(transform_1d_to_polynomial_features_, np.arange(0, 5, 0.01))))\n",
    "xx_scaled_rdd = scaler.transform(xx_powers_rdd)\n",
    "y_pred_rdd = xx_scaled_rdd.map(lambda x: model_linReg.predict(x))\n",
    "y_pred = y_pred_rdd.collect()\n",
    "\n",
    "# График\n",
    "plt.figure(1)\n",
    "plt.subplot(1,1,1)\n",
    "plt.plot(xx[0,:], y_pred, c=\"black\", label=\"\", linewidth=2)\n",
    "plt.title(\"Initial Data\")\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "for el in data_sample:\n",
    "    plt.plot(el.features[0], el.label, \"bo\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">2. Классификация</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"2a\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            a. Логистическая регрессия\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2b\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, LogisticRegressionWithLBFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Загрузите данные из файла</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>[ЕСЛИ НЕОБХОДИМО] Скопируйте локальный датасет в HDFS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal data/ml-basics-data/classification_demo.csv data/spark_mllib_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDFS\n",
    "data_path_class = \"hdfs:///YOUR_PATH/classification_demo.csv\"\n",
    "\n",
    "# Local file\n",
    "data_path_class = \"file:///YOUR_PATH/classification_demo.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rdd = sc.textFile(data_path_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Создайте RDD без первой строки (она содержит заголовки)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabeledPoint(line):\n",
    "    if line[0]!=\"X\":\n",
    "        els = [float(el) for el in line.split(\",\")]\n",
    "        return LabeledPoint(els[2], els[:2])\n",
    "    \n",
    "data_xy_rdd = data_rdd \\\n",
    "    .map(getLabeledPoint) \\\n",
    "    .filter(lambda x: x!= None)\n",
    "\n",
    "data_xy_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Отобразите исходных данных</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Initial Data\")\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "for el in data_xy_rdd.takeSample(withReplacement=False, num=80, seed=123):\n",
    "    plt.plot(el.features[0], el.features[1], \"o\", color=clrMap.colors[int(el.label)])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Сформируйте обучающее и тестовое подмножества</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rdd, test_rdd = data_xy_rdd.randomSplit([0.7, 0.3], seed=123)\n",
    "train_rdd.persist(), test_rdd.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Обучите модель логистической регрессии на обучающем подмножестве</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='https://spark.apache.org/docs/2.2.0/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionWithSGD'>LogisticRegressionWithSGD</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logReg = LogisticRegressionWithSGD.train(train_rdd, intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверьте результат обучения на тестовом подмножестве с использованием Accuracy</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairsTruePred_rdd = test_rdd.map(lambda x: (x.label, model_logReg.predict(x.features)))\n",
    "pairsTruePred_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pairsTruePred_rdd.filter(lambda x: x[0] == x[1]).count() / test_rdd.count()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Постройте итоговые графики</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sample = train_rdd.takeSample(withReplacement=False, num=80, seed=123)\n",
    "test_data_sample = test_rdd.takeSample(withReplacement=False, num=80, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0.1\n",
    "xx, yy = np.meshgrid(np.arange(-2, 14, step), np.arange(-4, 12, step))\n",
    "points = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = np.array(list(map(model_logReg.predict, points)))\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(1, figsize=[12, 4])\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Train data\")\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.contourf(xx, yy, Z, cmap=clrMap, alpha=.5)\n",
    "\n",
    "for el in train_data_sample:\n",
    "    plt.plot(el.features[0], el.features[1], \"o\", \n",
    "             color=clrMap.colors[int(el.label)], markersize=8, alpha=0.5)\n",
    "    plt.plot(el.features[0], el.features[1], \"o\", \n",
    "             color=clrMap.colors[int(model_logReg.predict(el.features))], markersize=4)\n",
    "    \n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Test data\")\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.contourf(xx, yy, Z, cmap=clrMap, alpha=.5)\n",
    "\n",
    "for el in test_data_sample:\n",
    "    plt.plot(el.features[0], el.features[1], \"o\", \n",
    "             color=clrMap.colors[int(el.label)], markersize=8, alpha=0.5)\n",
    "    plt.plot(el.features[0], el.features[1], \"o\", \n",
    "             color=clrMap.colors[int(model_logReg.predict(el.features))], markersize=4)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Сохраните модель</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logReg.save(sc, \"logReg\")\n",
    "#model_logReg_reload = LogisticRegressionModel.load(sc, \"logReg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"2b\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            b. Решающее дерево\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2a\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2c\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">3. Кластеризация</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"3a\"></a>\n",
    "<div style = \"display:table; width:100%\">\n",
    "    <div style = \"display:table-row\">\n",
    "        <div style = \"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            a. K-Means\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#3\">Назад</a>\n",
    "            </div>\n",
    "            <div style = \"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#3b\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import KMeans, KMeansModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Загрузите исходные данные из файла</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>[ЕСЛИ НЕОБХОДИМО] Скопируйте локальный датасет в HDFS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal data/ml-basics-data/clusters_demo.csv data/spark_mllib_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDFS\n",
    "data_path_cluster = \"hdfs:///YOUR_PATH/clusters_demo.csv\"\n",
    "\n",
    "# Local file\n",
    "data_path_cluster = \"file:///YOUR_PATH/clusters_demo.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rdd = sc.textFile(data_path_cluster)\n",
    "\n",
    "def getArray(x):\n",
    "    return np.array(list(map(float, x.split(\",\"))))\n",
    "\n",
    "data_arr_rdd = data_rdd.map(lambda x: getArray(x))\n",
    "data_arr_rdd.persist()\n",
    "data_arr_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Отобразите исходных данных</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in data_arr_rdd.takeSample(withReplacement=False, num=80, seed=123):\n",
    "    plt.plot(el[0], el[1], \"bo\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Initial Data\")\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Кластеризуйте данные K-means методом</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://spark.apache.org/docs/2.2.0/api/python/pyspark.mllib.html#pyspark.mllib.clustering.KMeans\">KMeans</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = KMeans.train(data_arr_rdd, k=3, maxIterations=10, initializationMode=\"k-means||\")\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rdd = data_arr_rdd.map(lambda x: clusters.predict(x)).zip(data_arr_rdd)\n",
    "result_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Постройте итоговые графики</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in result_rdd.takeSample(withReplacement=False, num=80, seed=123):\n",
    "    plt.plot(el[1][0], el[1][1], \"o\", color=clrMap.colors[el[0]])\n",
    "\n",
    "plt.grid(True)\n",
    "plt.title(\"Initial Data\")\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Сохраните модель кластеризации</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.save(sc, \"clusterModel\")\n",
    "#sameModel = KMeansModel.load(sc, \"clusterModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop the current Spark context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">4. Источники</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://spark.apache.org/docs/2.2.0/mllib-guide.html\">MLlib: RDD-based API</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
