{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\"><div><b><span style=\"font-weight:bold; color:green\">Spark</span> and Processing Customer Reviews</b></div>\n",
    "<div style=\"font-size:16pt; padding-top:20px;\">\n",
    "    Part 1. Interactive shell with Jupyter</div>\n",
    "</div><hr>\n",
    "<div style=\"text-align:right;\">Sergei Yu. Papulin <span style=\"font-style: italic;font-weight: bold;\">(papulin_bmstu@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "1. Word Count\n",
    "    - Developing application using interactive shell\n",
    "    - Running as single job\n",
    "    - Importing external modules\n",
    "2. Average Rating Calculation\n",
    "    - Developing application using interactive shell\n",
    "    - Importing external modules\n",
    "3. Stopping Spark Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>[OPTIONAL] <b>Environment Setup</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"]=\"/home/ubuntu/BigData/spark\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/home/ubuntu/ML/anaconda3/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/home/ubuntu/ML/anaconda3/bin/python\"\n",
    "\n",
    "spark_home = os.environ.get(\"SPARK_HOME\")\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python\"))\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python/lib/py4j-0.10.7-src.zip\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Run Spark Context</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run on **YARN** cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf = pyspark.SparkConf() \\\n",
    "#         .setAppName(\"reviewJupyterApp\") \\\n",
    "#         .setMaster(\"yarn\") \\\n",
    "#         .set(\"spark.submit.deployMode\", \"client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run **locally**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf() \\\n",
    "        .setAppName(\"reviewJupyterApp\") \\\n",
    "        .set(\"spark.executor.memory\", \"1g\") \\\n",
    "        .set(\"spark.executor.core\", \"2\") \\\n",
    "        .set(\"spark.driver.memory\", \"2g\") \\\n",
    "        .setMaster(\"local[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(conf=conf)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1,2,3,4,5,6,7,8,9]\n",
    "rdd_data = sc.parallelize(data)\n",
    "rdd_data_ = rdd_data.map(lambda x: x+1).map(lambda x: x+1)\n",
    "rdd_data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the context\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to a file in HDFS\n",
    "file_path = \"/YOUR_HDFS_PATH/samples_100.json\"\n",
    "output_path = \"/YOUR_HDFS_PATH/output\"\n",
    "\n",
    "# Local FS\n",
    "FILE_PATH = \"file:///home/ubuntu/BigData/datasets/samples_100.json\"\n",
    "OUTPUT_DIR_PATH = \"file:///home/ubuntu/BigData/datasets/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:16pt; font-weight:bold\">1. Word Count</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To Content</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing application using interactive shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "json_reviews_rdd = sc.textFile(FILE_PATH)\n",
    "json_reviews_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a text of reviews into words\n",
    "words_rdd = json_reviews_rdd\\\n",
    "    .flatMap(lambda row: json.loads(row)[\"reviewText\"].split(\" \"))\n",
    "words_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairs (word, 1)\n",
    "wcount_pair_rdd = words_rdd.map(lambda word: (word, 1))\n",
    "wcount_pair_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words\n",
    "wcount_rdd = wcount_pair_rdd.reduceByKey(lambda v1, v2: v1 + v2)\n",
    "wcount_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the RDD by values\n",
    "wcount_sorted_rdd = wcount_rdd.sortBy(lambda x: -x[1])\n",
    "wcount_sorted_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the output\n",
    "wcount_out_rdd = wcount_sorted_rdd.map(lambda x: \"{}\\t{}\".format(x[0], x[1]))\n",
    "wcount_out_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result to HDFS\n",
    "wcount_out_rdd.coalesce(1).saveAsTextFile(OUTPUT_DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "wcount_in_rdd = sc.textFile(output_path + \"/*\")\n",
    "wcount_in_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running as single job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the output directory\n",
    "# OUTPUT_DIR_PATH_ = OUTPUT_DIR_PATH.replace(\"file://\", \"\")\n",
    "# !rm -fR $OUTPUT_DIR_PATH_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # Chain of transformations\n",
    "# wcount_out_rdd = sc.textFile(FILE_PATH) \\\n",
    "#     .flatMap(lambda row: json.loads(row)[\"reviewText\"].split(\" \")) \\\n",
    "#     .map(lambda word: (word, 1)) \\\n",
    "#     .reduceByKey(lambda v1, v2: v1 + v2) \\\n",
    "#     .sortBy(lambda x: -x[1]) \\\n",
    "#     .map(lambda x: \"{}\\t{}\".format(x[0], x[1])) \\\n",
    "#     .coalesce(1)\n",
    "\n",
    "# # Start job\n",
    "# wcount_out_rdd.saveAsTextFile(OUTPUT_DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain of transformations\n",
    "wcount_out_rdd = (\n",
    "    sc.textFile(FILE_PATH)\n",
    "    .flatMap(lambda row: json.loads(row)[\"reviewText\"].split(\" \"))\n",
    "    .map(lambda word: (word, 1))\n",
    "    .reduceByKey(lambda v1, v2: v1 + v2)\n",
    "    .sortBy(lambda x: -x[1])\n",
    "    .map(lambda x: \"{}\\t{}\".format(x[0], x[1]))\n",
    "    .coalesce(1)\n",
    ")\n",
    "\n",
    "# Start job\n",
    "wcount_out_rdd.saveAsTextFile(OUTPUT_DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local\n",
    "!ls $OUTPUT_DIR_PATH_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDFS\n",
    "# !hdfs dfs -ls /YOUR_PATH/data/spark-rdd-intro/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **combineByKey**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_value(val):\n",
    "    return val\n",
    "\n",
    "def reduce_inside_partition(acc, val):\n",
    "    return acc + val\n",
    "    \n",
    "def reduce_partitions(acc, val):\n",
    "    return acc + val\n",
    "\n",
    "wcount_out_rdd = sc.textFile(FILE_PATH) \\\n",
    "    .flatMap(lambda row: json.loads(row)[\"reviewText\"].split(\" \")) \\\n",
    "    .map(lambda word: (word, 1)) \\\n",
    "    .combineByKey(init_value, reduce_inside_partition, reduce_partitions) \\\n",
    "    .sortBy(lambda x: -x[1]) \\\n",
    "    .map(lambda x: \"{}\\t{}\".format(x[0], x[1]))\n",
    "\n",
    "wcount_out_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing external modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(items):\n",
    "    \"\"\"Parse rows within each partition\"\"\"\n",
    "    import json\n",
    "    for item in items:\n",
    "        try:\n",
    "            for word in json.loads(str(item))[\"reviewText\"].split(\" \"):\n",
    "                yield (word, 1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "# Check the function\n",
    "json_reviews = json_reviews_rdd.take(2)\n",
    "for item in extract_words(json_reviews):\n",
    "    print(item)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain of transformations\n",
    "wcount_out_rdd = sc.textFile(FILE_PATH) \\\n",
    "    .mapPartitions(extract_words) \\\n",
    "    .reduceByKey(lambda v1, v2: v1 + v2) \\\n",
    "    .sortBy(lambda x: -x[1]) \\\n",
    "    .map(lambda x: \"{}\\t{}\".format(x[0], x[1])) \n",
    "\n",
    "\n",
    "# Start job\n",
    "wcount_out_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:16pt; font-weight:bold\">2. Average Rating Calculation</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To Content</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing application using interactive shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_reviews_rdd = sc.textFile(FILE_PATH)\n",
    "json_reviews_rdd.persist()\n",
    "json_reviews_rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average ratings for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prod_rating(item):\n",
    "    try:\n",
    "        review = json.loads(item)\n",
    "        return review[\"asin\"], float(review[\"overall\"])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Check the function\n",
    "single_review = json_reviews_rdd.take(1)[0]\n",
    "extract_prod_rating(single_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_rating_rdd = json_reviews_rdd.map(extract_prod_rating)\n",
    "prod_rating_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_prod_rating_rdd = prod_rating_rdd \\\n",
    "    .aggregateByKey((0,0), \n",
    "                    lambda x, value: (x[0] + value, x[1] + 1), \n",
    "                    lambda x, y: (x[0] + y[0], x[1] + y[1])) \\\n",
    "    .mapValues(lambda x: x[0]/x[1])\n",
    "\n",
    "avg_prod_rating_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average rating of all products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rating(item):\n",
    "    try:\n",
    "        rating = float(json.loads(item)[\"overall\"])\n",
    "        return rating\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_rating_rdd = json_reviews_rdd \\\n",
    "    .map(lambda row: extract_rating(row)) \\\n",
    "    .filter(lambda rating: rating is not None)\n",
    "\n",
    "prod_rating_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_count = prod_rating_rdd \\\n",
    "    .aggregate((0,0), \n",
    "               lambda x, value: (x[0] + value, x[1] + 1),\n",
    "               lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "\n",
    "avg_rating = rating_count[0] / rating_count[1]\n",
    "avg_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or in this way\n",
    "rating_sum = prod_rating_rdd.reduce(lambda x, y: x + y)\n",
    "n = prod_rating_rdd.count()\n",
    "avg_rating = rating_sum / n\n",
    "avg_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter items by their ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable\n",
    "# Note: if you don't use a broadcast variable \n",
    "#  this value will be copied to each task.\n",
    "#  For small data it's acceptable\n",
    "rating_threshold = 5\n",
    "\n",
    "# Broadcast\n",
    "rating_threshold_br = sc.broadcast(rating_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_rating(item):\n",
    "    try:\n",
    "        rating = float(json.loads(item)[\"overall\"])\n",
    "        return rating >= rating_threshold_br.value\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_rdd = json_reviews_rdd.filter(filter_by_rating)\n",
    "items_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing external modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average ratings for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prod_rating_per_partition(items):\n",
    "    import json\n",
    "    for item in items:\n",
    "        try:\n",
    "            review = json.loads(item)\n",
    "            yield review[\"asin\"], float(review[\"overall\"])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "# Check the function\n",
    "json_reviews = json_reviews_rdd.take(2)\n",
    "for item in extract_prod_rating_per_partition(json_reviews):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_prod_rating_rdd = sc.textFile(FILE_PATH) \\\n",
    "    .mapPartitions(extract_prod_rating_per_partition) \\\n",
    "    .aggregateByKey((0,0), \n",
    "                    lambda x, value: (x[0] + value, x[1] + 1), \n",
    "                    lambda x, y: (x[0] + y[0], x[1] + y[1])) \\\n",
    "    .mapValues(lambda x: x[0]/x[1])\n",
    "\n",
    "avg_prod_rating_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:16pt; font-weight:bold\">3. Stopping Spark Context</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To Content</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
