{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\"><b>Spam Classification with </b> <span style=\"font-weight:bold; color:green\">Spark Streaming</span></div><hr>\n",
    "<div style=\"text-align:right;\">S. Yu. Papulin <span style=\"font-style: italic;font-weight: bold;\">(papulin_bmstu@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Do not run the code below in this jupyter notebook. You have to combine all pieces of code to a single file and run it in terminal</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>1. Classification model</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-warning\">\n",
    "  <p class=\"msg-text-warn\">This model is just for demonstration purpose as some important steps are omitted such as preprocessing input message, model selection, testing etc.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pnd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# ====================================\n",
    "#\n",
    "# INPUT DATA FOR TRAINING\n",
    "#\n",
    "# ====================================\n",
    "\n",
    "# Dataframe columns\n",
    "columns = [\"class\", \"message\"]\n",
    "\n",
    "# Convertor: names to numbers\n",
    "def convert2bool(el):\n",
    "    return 0 if el == \"ham\" else 1\n",
    "\n",
    "# Convertor list for dataframe column transformation at init state\n",
    "converters = {\"class\": convert2bool}\n",
    "\n",
    "# Creating pandas dataframe\n",
    "df = pnd.read_csv(\"/FULL_PATH/data/SMSSpamCollection\", \n",
    "                  sep=\"\\t\",\n",
    "                  converters = converters,\n",
    "                  names=columns)\n",
    "\n",
    "\n",
    "# ====================================\n",
    "#\n",
    "# MODEL\n",
    "#\n",
    "# ====================================\n",
    "\n",
    "ngram = 1\n",
    "\n",
    "# TF-IDF model\n",
    "tf_idf_model = TfidfVectorizer(min_df=1, ngram_range=(1,ngram))\n",
    "\n",
    "# Converting input data (message) to tf-idf\n",
    "tf_idf = tf_idf_model.fit_transform(df[\"message\"]) \n",
    "\n",
    "# Init linear model for classification\n",
    "lr_model = LogisticRegression(penalty=\"l2\", \n",
    "                              fit_intercept=True, \n",
    "                              max_iter=100, \n",
    "                              C=1400,\n",
    "                              solver=\"lbfgs\", \n",
    "                              random_state=12345)\n",
    "\n",
    "# Training the model\n",
    "lr_model.fit(tf_idf, df[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>2. Spark Streaming App for classifying input message </b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "\n",
    "# Create Spark Context\n",
    "sc = SparkContext(appName=\"SpamClassification\")\n",
    "\n",
    "# Set log level\n",
    "#sc.setLogLevel(\"INFO\")\n",
    "\n",
    "# Transfer model to all nodes\n",
    "tf_idf_model_broadcast = sc.broadcast(tf_idf_model)\n",
    "lr_model_broadcast = sc.broadcast(lr_model)\n",
    "\n",
    "# Create Streaming Context\n",
    "ssc = StreamingContext(sc, 10)\n",
    "\n",
    "# Create a stream\n",
    "lines = ssc.socketTextStream(\"localhost\", 9999)\n",
    "\n",
    "# Create RDD with transformed messages to TF-IDF vector\n",
    "tf_idf_messages = lines.map(lambda row: (row, tf_idf_model_broadcast.value.transform([row])))\n",
    "\n",
    "def predic_message_class(message_tf_idf):\n",
    "    # Classify message\n",
    "    pred = lr_model_broadcast.value.predict(message_tf_idf)\n",
    "    return \"spam\" if pred[0] else \"ham\"\n",
    "\n",
    "# Create RDD for predictions\n",
    "predictions = tf_idf_messages.map(lambda row: (row[0], predic_message_class(row[1])))\n",
    "\n",
    "# Print the result (10 records) in terminal\n",
    "predictions.pprint()\n",
    "                                  \n",
    "# If you want to save the result in local files\n",
    "#predictions.transform(lambda rdd: rdd.coalesce(1)).saveAsTextFiles(\"FILE_PATH\")\n",
    "\n",
    "# Start Spark Streaming\n",
    "ssc.start()\n",
    "\n",
    "# Await terminiation\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>3. Running Spark Streaming app in terminal</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Combine above code into a single file and run the command below to start spark streaming application</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark-submit --master local[2] /YOUR_PATH/spark_streaming_spam_classification.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Every 10 seconds you must see in terminal a list of messages with minibatch timestamp. Now it's empty</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-------------------------------------------\n",
    "Time: 2018-11-15 02:58:11\n",
    "-------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>4. Testing App in terminal</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Open a new terminal window and use the netcat tool to create listener for the 9999 port</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc -lk 9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Enter some messages in terminal like \"free smartphone\" and click the Enter. See a result in the spark app terminal. Propably, you see something like the following</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-------------------------------------------\n",
    "Time: 2018-11-15 03:00:20\n",
    "-------------------------------------------\n",
    "('free smartphone ', 'spam')\n",
    "('send me documents', 'ham')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
