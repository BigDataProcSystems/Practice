{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognition using SynapseML\n",
    "\n",
    "---\n",
    "\n",
    "S.Yu. Papulin (papulin_bmstu@mail.ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load numpy and matplotlib related packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load spark related packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ubuntu/BigData/spark\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/home/ubuntu/ML/anaconda3/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/home/ubuntu/ML/anaconda3/bin/python\"\n",
    "\n",
    "spark_home = os.environ.get(\"SPARK_HOME\")\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python\"))\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python/lib/py4j-0.10.7-src.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType,\n",
    "    ArrayType, FloatType, IntegerType\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \n",
    "    import os\n",
    "    import urllib.request\n",
    "    import tarfile\n",
    "    import pickle\n",
    "    \n",
    "    \n",
    "    def show_download_progress():\n",
    "        received = 0\n",
    "        def _show_progress(num, size, total):\n",
    "            if num == 0:\n",
    "                nonlocal received\n",
    "                received = 0\n",
    "            received += size\n",
    "            print(\"{}/{}\".format(received, total), end=\"\\r\")\n",
    "        return _show_progress\n",
    "\n",
    "    \n",
    "    CIFAR_URL = \"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    CIFAR_LOCAL_PATH = \"/YOUR_PATH/data/cifar-106/cifar-10-python.tar.gz\"\n",
    "\n",
    "    # Load the dataset if there doesn't exist the dataset archive\n",
    "    if not os.path.isfile(CIFAR_LOCAL_PATH):\n",
    "        os.makedirs(os.path.dirname(CIFAR_LOCAL_PATH))\n",
    "        urllib.request.urlretrieve(CIFAR_URL, CIFAR_LOCAL_PATH, \n",
    "                                   reporthook=show_download_progress())\n",
    "\n",
    "    test_batch = None\n",
    "    meta_info = None\n",
    "\n",
    "    # Unpack the test set\n",
    "    with tarfile.open(CIFAR_LOCAL_PATH, \"r:gz\") as tar:\n",
    "        f = tar.extractfile(\"cifar-10-batches-py/test_batch\")\n",
    "        test_batch = pickle.load(f, encoding=\"latin1\")\n",
    "        f = tar.extractfile(\"cifar-10-batches-py/batches.meta\")\n",
    "        meta_info = pickle.load(f, encoding=\"latin1\")\n",
    "    \n",
    "    return test_batch, meta_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "test_batch, meta_info = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display meta \n",
    "meta_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label names\n",
    "meta_info[\"label_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys and values of the test set dictionary\n",
    "for key in test_batch.keys():\n",
    "    print(key, test_batch[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single image array\n",
    "test_batch[\"data\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array shape \n",
    "test_batch[\"data\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch[\"data\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DISPLAY_IMAGES = 10\n",
    "NUM_CLASSES = len(meta_info[\"label_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16, 2*NUM_CLASSES])\n",
    "\n",
    "labels = np.array(test_batch[\"labels\"])\n",
    "\n",
    "for i, name in enumerate(meta_info[\"label_names\"]):\n",
    "    image_indxs = np.random.choice(\n",
    "        np.where(labels==i)[0], \n",
    "        NUM_DISPLAY_IMAGES, \n",
    "        replace=False)\n",
    "    for j in range(NUM_DISPLAY_IMAGES):\n",
    "        reshaped_image = test_batch[\"data\"][image_indxs[j]]\\\n",
    "            .reshape(3, 32, 32)\\\n",
    "            .transpose(1, 2, 0)\\\n",
    "            .astype(\"uint8\")\n",
    "        plt.subplot(NUM_CLASSES, NUM_DISPLAY_IMAGES, j+i*NUM_DISPLAY_IMAGES+1)\n",
    "        plt.title(\"{}\".format(name))\n",
    "        plt.imshow(reshaped_image)\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf()\\\n",
    "        .setMaster(\"local[*]\")\\\n",
    "        .set(\"spark.jars.packages\", \"com.microsoft.ml.spark:mmlspark_2.11:0.18.0\")\\\n",
    "        .set(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"imageRecognition\")\\\n",
    "    .config(conf=conf)\\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load synapseml related packages\n",
    "from mmlspark.cntk import CNTKModel\n",
    "from mmlspark.downloader import ModelDownloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Image DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"label\", IntegerType(), True),\n",
    "    StructField(\"image\", ArrayType(FloatType()), True),\n",
    "    StructField(\"filename\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2float(row):\n",
    "    return row[0], row[1].astype(\"float\").tolist(), row[2]\n",
    "\n",
    "\n",
    "images = zip(test_batch[\"labels\"], test_batch[\"data\"], test_batch[\"filenames\"])\n",
    "\n",
    "df_images = spark.sparkContext\\\n",
    "    .parallelize(images)\\\n",
    "    .map(convert2float)\\\n",
    "    .toDF(schema)\n",
    "\n",
    "df_images.persist().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ConvNet\"\n",
    "model_dir = \"file:///tmp/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader = ModelDownloader(spark, model_dir)\n",
    "model = downloader.downloadByName(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntk_model = CNTKModel()\\\n",
    "    .setInputCol(\"image\")\\\n",
    "    .setOutputCol(\"output\")\\\n",
    "    .setModelLocation(model.uri)\\\n",
    "    .setOutputNode(\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images__predict_proba = cntk_model.transform(df_images)\n",
    "num_images = df_images__predict_proba.persist().count()\n",
    "num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images__predict_proba.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(IntegerType())\n",
    "def predict(proba):\n",
    "    return int(proba.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images__predict = df_images__predict_proba\\\n",
    "    .withColumn(\"prediction\", predict(\"output\"))\\\n",
    "    .select(\"prediction\", \"label\")\n",
    "\n",
    "df_images__predict.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "correct_count = df_images__predict\\\n",
    "    .where(F.col(\"prediction\") == F.col(\"label\"))\\\n",
    "    .count()\n",
    "\n",
    "correct_count / num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images__predict = df_images__predict.toPandas()\n",
    "y, y_hat = images__predict[\"label\"], images__predict[\"prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y, y_hat)\n",
    "\n",
    "plt.figure(figsize=[8,8])\n",
    "labels = meta_info[\"label_names\"]\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, labels, rotation=90)\n",
    "plt.yticks(tick_marks, labels)\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Model ConvNet CIFAR10](https://github.com/Microsoft/CNTK/blob/master/Examples/Image/Classification/ConvNet/BrainScript/ConvNet_CIFAR10.cntk)\n",
    "- [Ingesting CIFAR Images into Spark DataFrames and Evaluating Pre-Trained CNTK Models](https://github.com/microsoft/SynapseML/blob/v0.18.0/notebooks/samples/DeepLearning%20-%20CIFAR10%20Convolutional%20Network.ipynb)\n",
    "- [Ingesting CIFAR Images into Spark DataFrames and Evaluating Pre-Trained CNTK Models](https://notebook.community/rastala/mmlspark/notebooks/samples/301%20-%20CIFAR10%20CNTK%20CNN%20Evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
