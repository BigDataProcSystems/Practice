{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\"><b>Комбинация решающих деревьев и </b> <span style=\"font-weight:bold; color:green\">Spark MLlib</span></div><hr>\n",
    "<div style=\"text-align:right;\">Папулин С.Ю. <span style=\"font-style: italic;font-weight: bold;\">(papulin_bmstu@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name=\"0\"></a>\n",
    "<div><span style=\"font-size:14pt; font-weight:bold\">Содержание</span>\n",
    "    <ol>\n",
    "        <li><a href=\"#1\">Подключение библиотек и создание Spark контекста</a></li>\n",
    "        <li><a href=\"#2\">Загрузка исходных данных</a></li>\n",
    "        <li><a href=\"#3\">Анализ исходных данных</a></li>\n",
    "        <li><a href=\"#4\">Преобразование категориальных признаков в числовые</a>\n",
    "            <ol style = \"list-style-type:lower-alpha\">\n",
    "                <li><a href=\"#4a\">Заполнение ячеек с неопределенными значениями</a></li>\n",
    "                <li><a href=\"#4b\">Преобразование в натуральные числа</a></li>\n",
    "                <li><a href=\"#4c\">Преобразование в матрицу дискретных значений</a></li>\n",
    "                <li><a href=\"#4d\">Формирование вектора признаков</a></li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><a href=\"#5\">Решающие деревья и выбор модели</a>\n",
    "            <ol style = \"list-style-type:lower-alpha\">\n",
    "                <li><a href=\"#5a\">Формирование обучающего и тестового подмножеств</a></li>\n",
    "                <li><a href=\"#5b\">Вычисление базовой отметки</a></li>\n",
    "                <li><a href=\"#5c\">Random Forest и выбор модели</a></li>\n",
    "                <li><a href=\"#5d\">Gradient-boosted tree и выбор модели</a></li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><a href=\"#6\">Завершение работы</a></li>\n",
    "        <li><a href=\"#7\">Источники</a></li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Подключение стилей оформления</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<link href=\"css/style.css\" rel=\"stylesheet\" type=\"text/css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">1. Подключение библиотек и создание Spark контекста</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>[ОПЦИОНАЛЬНО] <b>Настройка среды</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"]=\"/opt/cloudera/parcels/SPARK2/lib/spark2\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/opt/rh/rh-python36/root/usr/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/opt/rh/rh-python36/root/usr/bin/python\"\n",
    "\n",
    "spark_home = os.environ.get(\"SPARK_HOME\")\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python\"))\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python/lib/py4j-0.10.7-src.zip\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Запуск Spark Session</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf() \\\n",
    "        .setAppName(\"treeApp\") \\\n",
    "        .setMaster(\"yarn\") \\\n",
    "        .set(\"spark.submit.deployMode\", \"client\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"treeApp\") \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">2. Загрузка исходных данных</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>[ЕСЛИ НЕОБХОДИМО]</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -mkdir -p data/spark_mllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal data/purchase-tree-data/train.csv data/spark_mllib/train.csv\n",
    "!hdfs dfs -copyFromLocal data/purchase-tree-data/test.csv data/spark_mllib/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls data/spark_mllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Путь к данными</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для Databricks\n",
    "# train_path = \"/FileStore/tables/z7yasv9p1492968987236/train.csv\"\n",
    "\n",
    "# Для Azure кластера\n",
    "# train_path = \"hdfs:///data/tree/train.csv\"\n",
    "train_path = \"data/spark_mllib/train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"msg-block msg-warning\">\n",
    "  <p class=\"msg-text-warn\">При использовании <span class=\"code-font\">file:///</span> метод <span class=\"code-font\">sqlContext.read.load()</span> может выдать ошибку</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchase = spark.read.load(train_path, \n",
    "                              format=\"csv\", \n",
    "                              header=\"true\", \n",
    "                              inferSchema=\"true\", \n",
    "                              sep=\",\")\n",
    "df_purchase.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_purchase.rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchase.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">3. Анализ исходных данных</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Количество элементов в выборке</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = df_purchase.count()\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Количество уникальных значений по столбцам</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exprs = [F.countDistinct(clmn).alias(clmn) for clmn in df_purchase.columns]\n",
    "exprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchase.agg(*exprs).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Уникальные значения по столбцам</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clmn in df_purchase.columns:\n",
    "    df_purchase[[clmn]].distinct().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Распределение по категориям</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender_local = df_purchase.groupBy(\"Gender\").count().toPandas()\n",
    "df_gender_local.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender_local[\"share\"] = df_gender_local[\"count\"].apply(lambda x: x / float(sample_size))\n",
    "df_gender_local.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_local = df_purchase.groupBy([\"Age\"]).count().toPandas()\n",
    "df_age_local[\"share\"] = df_age_local[\"count\"].apply(lambda x: x / float(sample_size))\n",
    "df_age_local.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(\"2\")\n",
    "\n",
    "width=0.25\n",
    "plt.bar(df_age_local.index-width/2.0, df_age_local[\"share\"], width)\n",
    "plt.xticks(df_age_local.index, df_age_local[\"Age\"])\n",
    "plt.xlabel(\"AGE\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>По нескольким столбцам</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender_age_local = df_purchase.groupBy([\"Gender\",\"Age\"]).count().toPandas()\n",
    "df_gender_age_local[\"share\"] = df_gender_age_local[\"count\"].apply(lambda x: x / float(sample_size))\n",
    "df_gender_age_local.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">4. Преобразование категориальных признаков в числовые</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4a\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            a. Заполнение ячеек с неопределенными значениями\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#4\">Назад</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#4b\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchase_na = df_purchase.na.fill({\"Product_Category_2\": 0, \"Product_Category_3\": 0})\n",
    "df_purchase_na.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4b\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            b. Преобразование в числовой вид\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#4a\">Назад</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#4c\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><i><b>Способ 1.</b> С использованием UDF</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(x):\n",
    "    if x == \"F\":\n",
    "        return 1.0\n",
    "    return 0.0\n",
    "  \n",
    "convert_gender = F.udf(lambda x: my_func(x), FloatType())\n",
    "\n",
    "df_purchase_na_gender = df_purchase_na.select(\"*\", convert_gender(df_purchase_na[\"Gender\"]).alias(\"GenderIndex\"))\n",
    "df_purchase_na_gender.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><i><b>Способ 2.</b> С использованием StringIndexer</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_indexer = StringIndexer(inputCol=\"Gender\", outputCol=\"GenderIndex\")\n",
    "df_purchase_na_gender = gender_indexer.fit(df_purchase_na).transform(df_purchase_na)\n",
    "df_purchase_na_gender.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Преобразование для столбцов Gender, Stay_In_Current_City_Years и Age</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Age имеет вид диапазонов. При преобразовании важно сохранить порядок</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Уникальные значения Age</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_pn = df_purchase.select(\"Age\").distinct().toPandas()\n",
    "df_age_pn.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Создание словаря, в котором каждому диапазону поставлено в соотвестие натуральное число</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_range_list = df_age_pn.sort_values(by=\"Age\", ascending=True).to_dict(\"list\")[\"Age\"]\n",
    "age_index = range(7)\n",
    "\n",
    "dict_age = dict(zip(age_range_list, age_index))\n",
    "dict_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Передача словаря всем executor'ам</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_age_brcst = spark.sparkContext.broadcast(dict_age)\n",
    "dict_age_brcst.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>UDF</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Вместо UDF лучше использовать стандарные операции над Dataframe. Например, F.when(col == \"F\", 1.0).otherwise(0.0)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gender_func(x):\n",
    "    if x == \"F\":\n",
    "        return 1.0\n",
    "    return 0.0\n",
    "\n",
    "def convert_stay_func(x):\n",
    "    if x == \"4+\":\n",
    "        return 5.0\n",
    "    return float(x)\n",
    "  \n",
    "def convert_age_func(x):\n",
    "    return float(dict_age_brcst.value[x])\n",
    "\n",
    "\n",
    "convert_gender = F.udf(lambda x: convert_gender_func(x), FloatType())\n",
    "convert_stay = F.udf(lambda x: convert_stay_func(x), FloatType())\n",
    "convert_age = F.udf(convert_age_func, FloatType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>Преобразование признаков и добавление их в исходный dataframe</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchase_converted = df_purchase_na.select(\"*\", \n",
    "                                             convert_gender(df_purchase_na[\"Gender\"]).alias(\"GenderIndex\"),\n",
    "                                             convert_stay(df_purchase_na[\"Stay_In_Current_City_Years\"]).alias(\"Stay_Index\"),\n",
    "                                             convert_age(df_purchase_na[\"Age\"]).alias(\"Age_Index\"))\n",
    "\n",
    "df_purchase_converted.persist().select(\"Age_Index\").distinct().show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4c\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            c. Преобразование в матрицу дискретных значений\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#4b\">Назад</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#4d\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Шаг 1.</b> Преобразование категориального признака в числовой с использованием StringIndexer</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_indexer = StringIndexer(inputCol=\"City_Category\", outputCol=\"City_Category_Index\")\n",
    "df_purchase_converted_city_indx = city_indexer.fit(df_purchase_converted).transform(df_purchase_converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Шаг 2.</b> Преобразование полученного посредством StringIndexer числового признака в набор чиловых признаков с использованием OneHotEncoder</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_encoder = OneHotEncoder(inputCol=\"City_Category_Index\", outputCol=\"City_Category_Cat\")\n",
    "df_purchase_full_converted = city_encoder.transform(df_purchase_converted_city_indx)\n",
    "df_purchase_full_converted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4d\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            d. Формирование вектора признаков\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#4b\">Назад</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#5\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><i><b>Способ 1.</b> С использованием UDF</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Преобразование столбца с разреженным представлением вектора значений от OneHotEncoder в полный вид (dense)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse2dense_funct(x):\n",
    "    return x.toArray().tolist()\n",
    "\n",
    "convert_sparse2dense = F.udf(lambda x: convert_sparse2dense_funct(x), ArrayType(FloatType()))\n",
    "\n",
    "df1 = df_purchase_full_converted.select(\n",
    "    convert_sparse2dense(df_purchase_full_converted[\"City_Category_Cat\"]).alias(\"City_Category_Cat\"))\n",
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Формирование столбца из множества других, объединяя их значения в вектор (массив)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\"GenderIndex\", \"Age_Index\", \"Marital_Status\", \"Stay_Index\", \n",
    "                    \"Product_Category_1\", \"Product_Category_2\", \"Product_Category_3\"]\n",
    "\n",
    "df2 = df_purchase_full_converted.select(F.array(selected_columns).alias(\"IndexArray\"), \n",
    "                                        convert_sparse2dense(df_purchase_full_converted[\"City_Category_Cat\"]).alias(\"City_Category_Cat\"), \n",
    "                                        df_purchase_full_converted[\"Purchase\"])\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Объединение столбцов</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_funct(x):\n",
    "    return x[0] + x[1]\n",
    "\n",
    "union = F.udf(lambda x: union_funct(x), ArrayType(FloatType()))\n",
    "\n",
    "df_features = df2.select(union(F.array(df2[\"IndexArray\"], df2[\"City_Category_Cat\"])).alias(\"Features\"), \n",
    "                         df2[\"Purchase\"]).persist()\n",
    "df_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><i><b>Способ 2.</b> С использованием VectorAssembler</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_assembler = VectorAssembler(inputCols=selected_columns+[\"City_Category_Cat\"],\n",
    "                                    outputCol=\"Features\")\n",
    "\n",
    "df_features_all = feature_assembler.transform(df_purchase_full_converted)\n",
    "df_features_all.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_features_all.select(\"Features\", \"Purchase\")\n",
    "df_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">5. Решающие деревья и выбор модели</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5a\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            a. Формирование обучающего и тестового подмножеств\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#5\">Назад</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#5b\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Разделение данных на обучающее и тестовое подмножества</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df_features.randomSplit([0.8, 0.2], seed=12)\n",
    "df_train.persist(); df_test.repartition(10).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5b\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            b. Вычисление базовой отметки\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#5a\">Назад</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#5c\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Вычисление среднего значения</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mean = df_train.select(F.mean(\"Purchase\").alias(\"avg_purchase\"))\n",
    "df_train_mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_purchase_mean = df_train_mean.collect()[0][\"avg_purchase\"]\n",
    "train_purchase_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Создание столбца со средним значением</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred_bl = df_test.withColumn(\"Prediction\", F.lit(train_purchase_mean)) # значение в lit передается всем executor'ам\n",
    "df_test_pred_bl.select(\"Prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Проверка на тестовом подмножестве</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_rmse = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Purchase\", predictionCol=\"Prediction\")\n",
    "eval_r2 = RegressionEvaluator(metricName=\"r2\", labelCol=\"Purchase\", predictionCol=\"Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_rmse.evaluate(df_test_pred_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_r2.evaluate(df_test_pred_bl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5c\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            c. Random Forest и выбор модели\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#5b\">Назад</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#5d\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Создание модели, обучение и тестирование</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Создание модели</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol=\"Features\", \n",
    "                           labelCol=\"Purchase\",  \n",
    "                           predictionCol=\"Prediction\", \n",
    "                           numTrees=10, \n",
    "                           maxDepth=10, \n",
    "                           seed=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Обучение</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf.fit(df_train)\n",
    "rf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Отображение значений важности признаков</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Предсказание для тестового подмножества</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred_rf = rf_model.transform(df_test)\n",
    "df_test_pred_rf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Тестирование</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_rmse.evaluate(df_test_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_r2.evaluate(df_test_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Выбор модели</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Создание базовой модели</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol=\"Features\", labelCol=\"Purchase\",  predictionCol=\"Prediction\", seed=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Формирование сетки параметров для моделей</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParamGridBuilder().addGrid(rf.numTrees, [10]) \\\n",
    "                         .addGrid(rf.maxDepth, [10]) \\\n",
    "                         .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Конфигурирования исходных данных для выбора модели с использованием кросс-валидации с k-folds</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=grid, evaluator=eval_rmse, numFolds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Запуск процесса выбора модели по заданной сетке параметров</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cv = cv.fit(df_train)\n",
    "m_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Отображение значений ошибок для всех моделей</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cv.avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Доступ к лучшей модели</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = m_cv.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Тестирование лучшей модели (без повторного обучения на df_train)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred_rf = bestModel.transform(df_test)\n",
    "eval_rmse.evaluate(df_test_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5d\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            d. Gradient-boosted tree и выбор модели\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#5c\">Назад</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#6\">Далее</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Создание модели</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(featuresCol=\"Features\", labelCol=\"Purchase\",  predictionCol=\"Prediction\", \n",
    "                   maxDepth=10, maxIter=20, stepSize=0.00001, minInstancesPerNode=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Обучение</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_model = gbt.fit(df_train)\n",
    "gbt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Отображение значений важности признаков</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Предсказание для тестового подмножества</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred_gbt = gbt_model.transform(df_test)\n",
    "df_test_pred_gbt.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Тестирование</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_rmse.evaluate(df_test_pred_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_r2.evaluate(df_test_pred_gbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Выбор модели</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Создание базовой модели</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(featuresCol=\"Features\", \n",
    "                   labelCol=\"Purchase\",  \n",
    "                   predictionCol=\"Prediction\",\n",
    "                   checkpointInterval=10, \n",
    "                   stepSize=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Формирование сетки параметров для моделей</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParamGridBuilder().addGrid(gbt.maxIter, [15]) \\\n",
    "                         .addGrid(gbt.maxDepth, [5]) \\\n",
    "                         .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Конфигурирования исходных данных для выбора модели с использованием кросс-валидации с k-folds</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=gbt, estimatorParamMaps=grid, evaluator=eval_rmse, numFolds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Запуск процесса выбора модели по заданной сетке параметров</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cv = cv.fit(df_train)\n",
    "m_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Отображение значений ошибок для всех моделей</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cv.avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Доступ к лучшей модели</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = m_cv.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Тестирование лучшей модели (без повторного обучения на df_train)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred_rf = bestModel.transform(df_test)\n",
    "eval_rmse.evaluate(df_test_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"6\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">6. Завершение работы</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Завершение Spark контекста</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"7\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">7. Источники</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">К содержанию</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://datahack.analyticsvidhya.com/contest/black-friday/\n",
    "https://www.analyticsvidhya.com/blog/2016/05/h2o-data-table-build-models-large-data-sets/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "tree",
  "notebookId": 3408648737232908
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
