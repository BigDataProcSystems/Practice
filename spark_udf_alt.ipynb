{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\"><b>PySpark and </b> <span style=\"font-weight:bold; color:green\">UDF</span></div><hr>\n",
    "<div style=\"text-align:right;\">Sergei Yu. Papulin <span style=\"font-style: italic;font-weight: bold;\">(papulin_bmstu@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"0\"></a>\n",
    "<div><span style=\"font-size:14pt; font-weight:bold\">Contents</span>\n",
    "    <ol>\n",
    "        <li><a href=\"#1\">Initial dataset</a></li>\n",
    "        <li><a href=\"#2\">Python UDF</a></li>\n",
    "        <li><a href=\"#3\">Java UDF in Python</a></li>\n",
    "        <li><a href=\"#4\">Pure Dataframe</a></li>\n",
    "        <li><a href=\"#5\">Pandas UDF</a></li>\n",
    "        <li><a href=\"#6\">Sources</a></li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>[OPTIONAL] <b>Environment Setup</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SPARK_HOME\"]=\"/opt/cloudera/parcels/SPARK2/lib/spark2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_PYTHON\"]=\"/opt/rh/rh-python36/root/usr/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/opt/rh/rh-python36/root/usr/bin/python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_home = os.environ.get(\"SPARK_HOME\")\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python\"))\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python/lib/py4j-0.10.7-src.zip\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Configurations</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf() \\\n",
    "        .setAppName(\"udfApp\") \\\n",
    "        .setMaster(\"yarn-client\") \\\n",
    "        .set(\"spark.jars\", \"/home/cloudera/workspace/CLASS_UDF/lib/*\")\n",
    "        #.set(\"spark.driver.extraClassPath\", \"/home/cloudera/workspace/CLASS_UDF/lib/*\") \\\n",
    "        #.set(\"spark.executor.extraClassPath\", \"/home/cloudera/workspace/CLASS_UDF/lib/*\")\n",
    "        \n",
    "#pyspark2 --master local[2] --driver-class-path /home/cloudera/workspace/CLASS_UDF/lib/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>New versions (Spark 2+)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"udfApp\") \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Older versions</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">1. Initial dataset</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To contents</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create initial dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = [[0, \"Dima\", \"Moscow\", 1988, 4, \"m\"],\n",
    "           [1, \"Sveta\", \"Kiev\", 1999, 4, \"f\"],\n",
    "           [2, \"Alex\", \"Minsk\", 1954, 8, \"m\"],\n",
    "           [3, \"Ivan\", \"St.Petersburg\", 2005, 6, \"m\"],\n",
    "           [4, \"Kate\", \"London\", 2001, 3, \"f\"],\n",
    "           [5, \"Maria\", \"New York\", 1997, 7, \"f\"]]\n",
    "persons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>RDD API</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_rdd = sc.parallelize(persons)\n",
    "person_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Dataframe API</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, LongType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(name=\"Id\", dataType=IntegerType(), nullable=False),\n",
    "                     StructField(\"Name\", StringType(), True),\n",
    "                     StructField(\"City\", StringType(), True),\n",
    "                     StructField(\"Year\", IntegerType(), True),\n",
    "                     StructField(\"Grade\", IntegerType(), True),\n",
    "                     StructField(\"Gender\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df = spark.createDataFrame(person_rdd, schema)\n",
    "person_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">2. Python UDF</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To contents</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Function for UDF to convert a numerical grade to a letter</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conver2letter_grade(x):\n",
    "    return \"F\" if x < 5 else \"A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>RDD API</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_with_letter_rdd = person_rdd.map(lambda row: conver2letter_grade(row[4]))\n",
    "person_with_letter_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_with_letter_rdd.toDebugString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Dataframe API</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create a UDF function for a dataframe</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert2letter_udf = F.udf(lambda x: conver2letter_grade(x), StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Apply the udf to our dataframe </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_with_letter_df = person_df.select(convert2letter_udf(person_df[\"Grade\"]).alias(\"LetterGrade\"))\n",
    "person_with_letter_df.explain()\n",
    "person_with_letter_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">3. Java UDF in Python</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To contents</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create a new Java project</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Add the following modules to your Java project (from Maven)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org.apache.spark:spark-core_2.10\n",
    "org.apache.spark:spark-sql_2.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Copy-paste the code of the custom udf</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package edu.spark.customsparkudf;\n",
    "\n",
    "import org.apache.spark.sql.api.java.UDF1;\n",
    "\n",
    "public class CategorizeValue implements UDF1<Integer, String> {\n",
    "\n",
    "    private static final long serialVersionUID = 1L;\n",
    "\n",
    "    @Override\n",
    "    public String call(Integer value) throws Exception {\n",
    "        if (value < 5) return \"F\";\n",
    "        return \"A\";\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create jar file</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This jar file should be distributed across all spark nodes as shown below or as the --jars argument for the spark-submit command</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf = pyspark.SparkConf() \\\n",
    "#         .setAppName(\"udfApp\") \\\n",
    "#         .setMaster(\"yarn-client\") \\\n",
    "#         .set(\"spark.jars\", \"/home/cloudera/workspace/CLASS_UDF/lib/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Apply Java UDF inside Python</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.sql.warehouse.dir\", \"/home/cloudera/workspace/CLASS_UDF/lib/*\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.udf.registerJavaFunction(\"categorize\", \"edu.spark.customsparkudf.CategorizeValue\", StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_with_letter_java_df = person_df.selectExpr(\"categorize(Grade) as LetterGrade\")\n",
    "person_with_letter_java_df.explain()\n",
    "person_with_letter_java_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">4. Pure Dataframe</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To contents</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create SQL-like expression</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conver2letter_grade_sql(col):\n",
    "    return F.when(col < 5, \"F\").otherwise(\"A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Apply the function</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_with_letter_df = person_df.select(conver2letter_grade_sql(F.col(\"Grade\")).alias(\"LetterGrade\"))\n",
    "person_with_letter_df.explain()\n",
    "person_with_letter_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">5. Pandas UDF</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To contents</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Stop Spark Context</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"6\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">6. Sources</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To contents</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
