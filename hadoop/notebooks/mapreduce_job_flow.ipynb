{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\"><span style=\"font-weight:bold; color:green\">MapReduce</span> <b>Workflow and Data Serialization Systems</b></div><hr>\n",
    "<div style=\"text-align:right;\">Sergei Yu. Papulin <span style=\"font-style: italic;font-weight: bold;\">(papulin_bmstu@mail.ru, papulin_hse@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"0\"></a>\n",
    "<div><span style=\"font-size:14pt; font-weight:bold\">Content</span>\n",
    "    <ol>\n",
    "        <li><a href=\"#1\">MapReduce Workflow</a>\n",
    "            <ol style = \"list-style-type:lower-alpha\">\n",
    "                <li><a href=\"#1a\">ControlFlow</a></li>\n",
    "                <li><a href=\"#1b\">Oozie</a></li>\n",
    "                <li><a href=\"#1c\">Tez</a></li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><a href=\"#2\">Data Serialization Systems</a>\n",
    "            <ol style = \"list-style-type:lower-alpha\">\n",
    "                <li><a href=\"#2a\">Java</a></li>\n",
    "                <li><a href=\"#2b\">Avro</a></li>\n",
    "                <li><a href=\"#2c\">Parquet</a></li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><a href=\"#3\">References</a></li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Launch the cell below to apply a jupyter notebook style</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href=\"css/style.css\" rel=\"stylesheet\" type=\"text/css\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<link href=\"css/style.css\" rel=\"stylesheet\" type=\"text/css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">1. MapReduce Workflow</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To Content</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1a\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            a. ControlFlow\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#1\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#1b\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Creating a jar file with a workflow</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<p>Create a new project in <span class=\"code-font\">IntelliJ</span>, and copy the following files to the current project:</p> \n",
    "<ul><li class=\"code-font\">ProdAvgMapper.java</li>\n",
    "    <li class=\"code-font\">ProdAvgCombiner.java</li>\n",
    "    <li class=\"code-font\">ProdAvgReducer.java</li>\n",
    "    <li class=\"code-font\">SumCountWritable.java</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Replace a package name with <span class=\"code-font\">edu.classes.mrjobflow</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create additional java files in your project with contents displayed below. Package is <span class=\"code-font\">edu.classes.mrjobflow</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"code-font\">GroupMapper.java</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.mrjobflow;\n",
    "\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Mapper;\n",
    "\n",
    "import java.io.IOException;\n",
    "\n",
    "public class GroupMapper extends Mapper<Object, Text, IntWritable, IntWritable> {\n",
    "\n",
    "    private IntWritable one = new IntWritable(1);\n",
    "    private IntWritable group = new IntWritable();\n",
    "\n",
    "    public void map(Object key, Text value, Context context\n",
    "    ) throws IOException, InterruptedException {\n",
    "\n",
    "\n",
    "        String prod_rating = value.toString();\n",
    "        String[] items = prod_rating.split(\"\\t\");\n",
    "\n",
    "        if (items.length == 2) {\n",
    "\n",
    "            double rating = Double.valueOf(items[1]);\n",
    "\n",
    "            if (rating >= 0 && rating < 1) {\n",
    "                group.set(1);\n",
    "                context.write(group, one);\n",
    "            } else if (rating >= 1 && rating < 2) {\n",
    "                group.set(2);\n",
    "                context.write(group, one);\n",
    "            } else if (rating >= 2 && rating < 3) {\n",
    "                group.set(3);\n",
    "                context.write(group, one);\n",
    "            } else if (rating >= 3 && rating < 4) {\n",
    "                group.set(4);\n",
    "                context.write(group, one);\n",
    "            } else if (rating >= 4 && rating <= 5) {\n",
    "                group.set(5);\n",
    "                context.write(group, one);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"code-font\">GroupReducer.java</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.mrjobflow;\n",
    "\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.mapreduce.Reducer;\n",
    "\n",
    "import java.io.IOException;\n",
    "\n",
    "public class GroupReducer extends Reducer<IntWritable,IntWritable,IntWritable,IntWritable> {\n",
    "\n",
    "    private IntWritable resultCount = new IntWritable();\n",
    "\n",
    "    public void reduce(IntWritable key, Iterable<IntWritable> values, Context context)\n",
    "            throws IOException, InterruptedException {\n",
    "\n",
    "        int count = 0;\n",
    "\n",
    "        for (IntWritable val : values) {\n",
    "            count += val.get();\n",
    "        }\n",
    "\n",
    "        System.out.println(key + \" : \" + count);\n",
    "\n",
    "        resultCount.set(count);\n",
    "\n",
    "        context.write(key, resultCount);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"code-font\">JobFlowDriver.java</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "package edu.classes.mrjobflow;\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n",
    "import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n",
    "import org.apache.hadoop.mapred.jobcontrol.JobControl;\n",
    "import org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob;\n",
    "import org.apache.hadoop.mapreduce.Job;\n",
    "\n",
    "import java.util.List;\n",
    "\n",
    "public class JobFlowDriver {\n",
    "\n",
    "    public void run(String[] args) throws Exception {\n",
    "\n",
    "        JobControl jobControl = new JobControl(\"MapReduceJobFlow\");\n",
    "\n",
    "        // Job 1 ----------------------------------------------\n",
    "        // Create a configuration for the first job\n",
    "        Configuration confAvgJob = new Configuration();\n",
    "\n",
    "        // Create a job for calculating average product ratings\n",
    "        Job avgJob = Job.getInstance(confAvgJob, \"ProdAverageRating\");\n",
    "        avgJob.setJarByClass(JobFlowDriver.class);\n",
    "        avgJob.setMapperClass(ProdAvgMapper.class);\n",
    "        avgJob.setCombinerClass(ProdAvgCombiner.class);\n",
    "        avgJob.setReducerClass(ProdAvgReducer.class);\n",
    "        avgJob.setOutputKeyClass(Text.class);\n",
    "        avgJob.setOutputValueClass(SumCountWritable.class);\n",
    "        FileInputFormat.addInputPath(avgJob, new Path(args[0]));\n",
    "        FileOutputFormat.setOutputPath(avgJob, new Path(args[1]));\n",
    "\n",
    "        // Create a JobControl container for avgJob\n",
    "        ControlledJob cntrAvgJob = new ControlledJob(confAvgJob);\n",
    "        cntrAvgJob.setJob(avgJob);\n",
    "\n",
    "        // Add the JobControl container to JobControl\n",
    "        jobControl.addJob(cntrAvgJob);\n",
    "        //-----------------------------------------------------\n",
    "\n",
    "        // Job 2 ----------------------------------------------\n",
    "        Configuration confGroupJob = new Configuration();\n",
    "        Job groupJob = Job.getInstance(confGroupJob, \"GroupProdByRating\");\n",
    "        groupJob.setJarByClass(JobFlowDriver.class);\n",
    "        groupJob.setMapperClass(GroupMapper.class);\n",
    "        groupJob.setCombinerClass(GroupReducer.class);\n",
    "        groupJob.setReducerClass(GroupReducer.class);\n",
    "        groupJob.setOutputKeyClass(IntWritable.class);\n",
    "        groupJob.setOutputValueClass(IntWritable.class);\n",
    "        FileInputFormat.addInputPath(groupJob, new Path(args[1]));\n",
    "        FileOutputFormat.setOutputPath(groupJob, new Path(args[2]));\n",
    "\n",
    "        // Create a JobControl container for groupJob\n",
    "        ControlledJob cntrGroupJob = new ControlledJob(confGroupJob);\n",
    "        cntrGroupJob.setJob(groupJob);\n",
    "\n",
    "        // Create a dependency Job 1 -> Job 2\n",
    "        cntrGroupJob.addDependingJob(cntrAvgJob);\n",
    "\n",
    "\n",
    "        jobControl.addJob(cntrGroupJob);\n",
    "        //-----------------------------------------------------\n",
    "\n",
    "        Thread jobControlRunner = new Thread(jobControl);\n",
    "        jobControlRunner.start();\n",
    "\n",
    "        long startTime = System.currentTimeMillis();\n",
    "\n",
    "        while (!jobControl.allFinished()) {\n",
    "            System.out.println(\"Jobs in waiting state: \" + jobControl.getWaitingJobList().size());\n",
    "            System.out.println(\"Jobs in ready state: \"   + jobControl.getReadyJobsList().size());\n",
    "            System.out.println(\"Jobs in running state: \" + jobControl.getRunningJobList().size());\n",
    "            System.out.println(\"Jobs in success state: \" + jobControl.getSuccessfulJobList().size());\n",
    "            System.out.println(\"Jobs in failed state: \"  + jobControl.getFailedJobList().size());\n",
    "            System.out.println(\"\\n\");\n",
    "\n",
    "            try {\n",
    "                Thread.sleep(10 * 1000);\n",
    "            } catch (Exception e) {\n",
    "\n",
    "            }\n",
    "        }\n",
    "\n",
    "        long endTime = System.currentTimeMillis();\n",
    "\n",
    "        List<ControlledJob> fail = jobControl.getFailedJobList();\n",
    "        List<ControlledJob> succeed = jobControl.getSuccessfulJobList();\n",
    "\n",
    "        int numOfSuccessfulJob = succeed.size();\n",
    "        if (numOfSuccessfulJob > 0) {\n",
    "            System.out.println(numOfSuccessfulJob + \" jobs succeeded\");\n",
    "        }\n",
    "\n",
    "        int numOfFailedjob = fail.size();\n",
    "        if (numOfFailedjob > 0) {\n",
    "            System.out.println(\"------------------------------- \");\n",
    "            System.out.println(numOfFailedjob + \" jobs failed\");\n",
    "        }\n",
    "\n",
    "        System.out.println(\"JobFlow results:\");\n",
    "        System.out.println(\"Total num of Jobs: \" + 2);\n",
    "        System.out.println(\"ExecutionTime: \" + ((endTime-startTime) / 1000));\n",
    "        jobControl.stop();\n",
    "\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) throws Exception {\n",
    "        JobFlowDriver jobFlow = new JobFlowDriver();\n",
    "        jobFlow.run(args);\n",
    "    }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Running on an EMR cluster</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create a json file to specify a jobflow step</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load /YOUR_PATH/config/jobflow-step-template.json\n",
    "[\n",
    "  {\n",
    "     \"Name\": \"JobFlow Step\",\n",
    "     \"Type\": \"CUSTOM_JAR\",\n",
    "     \"ActionOnFailure\": \"TERMINATE_CLUSTER\",\n",
    "     \"Jar\": \"s3://YOUR_BUCKET/jobflow/MapReduceJobFlow.jar\",\n",
    "     \"Args\": [\n",
    "         \"s3://YOUR_BUCKET/data/reviews_Electronics_5.json\",\n",
    "         \"s3://YOUR_BUCKET/data/temp_jobflow\",\n",
    "         \"s3://YOUR_BUCKET/data/output_jobflow\"]\n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create an EMR cluster with the jobflow step</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-info\">\n",
    "  <div class=\"msg-text-info\">\n",
    "      <p>1) find out your subnet where a cluster will be run</p>\n",
    "      <p class=\"code-block code-font\">aws ec2 <span class=\"code-key\">describe-subnets</span></p>\n",
    "      <p>2) create a S3 bucket (if needed)</p>\n",
    "      <p class=\"code-block code-font\">aws s3 <span class=\"code-key\">mb</span> s3://YOUR_BUCKET/</p>\n",
    "      <p>3) copy a file with bootstrap actions and your bucket name to S3</p>\n",
    "      <p class=\"code-block code-font\">aws s3 <span class=\"code-key\">cp</span> /YOUR_PATH/config/download-unzip-s3.sh s3://YOUR_BUCKET/scripts/download-unzip-s3.sh</p>\n",
    "      <p>4) copy the jobflow jar file to S3</p>\n",
    "      <p class=\"code-block code-font\">aws s3 <span class=\"code-key\">cp</span> /YOUR_PATH/MapReduceJobFlow.jar s3://YOUR_BUCKET/jobflow/MapReduceJobFlow.jar</p>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws emr create-cluster \\\n",
    "    --name \"Hadoop_Cluster\" \\\n",
    "    --release-label emr-5.8.0 \\\n",
    "    --applications Name=Hadoop Name=Zeppelin \\\n",
    "    --log-uri s3://your_bucket/logs/ \\\n",
    "    --service-role emr-default-role \\\n",
    "    --instance-groups InstanceGroupType=MASTER,InstanceCount=1,InstanceType=m4.large InstanceGroupType=CORE,InstanceCount=3,InstanceType=m4.large \\\n",
    "    --ec2-attributes InstanceProfile=emr-default-ec2-role,KeyName=BigData_Keys,SubnetId=YOUR_SUBNET \\\n",
    "    --bootstrap-action Path=s3://YOUR_BUCKET/download-unzip-s3.sh \\\n",
    "    --configurations file:///YOUR_PATH/config/hdfs-config.json \\\n",
    "    --steps file:///YOUR_PATH/config/jobflow-step.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Set up an SSH tunnel using dynamic port forwarding (run in your terminal)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo aws emr socks --cluster-id YOUR_CLUSTER_ID --key-pair-file /YOUR_PATH/bigdata_keys.pem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-ref\">\n",
    "      <div class=\"msg-text-ref\">\n",
    "          <p>To connect to hadoop web dashboards, see the following guides: <br>\n",
    "          <a href=\"http://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-ssh-tunnel.html\">Part 1: Set Up an SSH Tunnel to the Master Node Using Dynamic Port Forwarding</a><br>\n",
    "          <a href=\"http://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-connect-master-node-proxy.html\">Part 2: Configure Proxy Settings to View Websites Hosted on the Master Node</a>\n",
    "          </p>\n",
    "     </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Print out an internal host name of the master node</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!aws emr list-instances \\\n",
    "        --cluster-id YOUR_CLUSTER_ID \\\n",
    "        --instance-group-types \"MASTER\" \\\n",
    "        --query \"Instances[0].PrivateDnsName\" \\\n",
    "        --output text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Use the hostname to connect to hadoop web dashboards. For exmpale,</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"code-block code-font\" href=\"http://ip-10-0-1-14.eu-west-1.compute.internal:8088\">ip-10-0-1-14.eu-west-1.compute.internal:8088</a> (ResourceManager dashboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Display steps and their states </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!aws emr list-steps --cluster-id YOUR_CLUSTER_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>After the jobflow step will be completed, check the output directory</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sudo aws s3 ls s3://YOUR_BUCKET/data/output_jobflow/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Display an output file</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sudo aws s3 cp --quiet s3://YOUR_BUCKET/data/output_jobflow/part-r-00000 /dev/stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-imp\">\n",
    "  <div class=\"msg-text-imp\"><p>\n",
    "      Don't forget to terminate the cluster, otherwise your free subscription runs out quickly. A rule of thumb is that you terminate the cluster after all job is completed. There are two options to do this:<br>\n",
    "      1) <span class=\"code-font\">EMR -> Select Cluster -> Terminate</span><br>\n",
    "      2) AWS CLI: <span class=\"code-font\">aws emr terminate-clusters --cluster-ids j-xxxxx</span>\n",
    "      \n",
    "  </p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Terminate the cluster</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!aws emr terminate-clusters --cluster-ids YOUR_CLUSTER_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Check that all clusters are terminated</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!aws emr list-clusters --active "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1b\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            b. Oozie\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#1a\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#1c\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Creating configuration files with a workflow description</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create two jar files - <span class=\"code-font\">ProdAvgRatingApp.jar</span> and <span class=\"code-font\">GroupProdRating.jar</span> - and copy them to <span class=\"code-font\">/YOUR_PATH/oozie-project/lib</span>. Use the files from the previous section for that. In addition, to create <span class=\"code-font\">GroupProdRating.jar</span>, use the driver below</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"code-font\">GroupDriver.java</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.mrjobflow;\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.conf.Configured;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.mapreduce.Job;\n",
    "import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n",
    "import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n",
    "import org.apache.hadoop.util.Tool;\n",
    "import org.apache.hadoop.util.ToolRunner;\n",
    "\n",
    "public class GroupDriver extends Configured implements Tool {\n",
    "\n",
    "    public int run(String[] args) throws Exception {\n",
    "\n",
    "        Job job = Job.getInstance(getConf(), \"GroupProdRating\");\n",
    "        job.setJarByClass(GroupDriver.class);\n",
    "        job.setMapperClass(GroupMapper.class);\n",
    "        job.setCombinerClass(GroupReducer.class);\n",
    "        job.setReducerClass(GroupReducer.class);\n",
    "        job.setOutputKeyClass(IntWritable.class);\n",
    "        job.setOutputValueClass(IntWritable.class);\n",
    "        FileInputFormat.addInputPath(job, new Path(args[0]));\n",
    "        FileOutputFormat.setOutputPath(job, new Path(args[1]));\n",
    "        return job.waitForCompletion(true) ? 0 : 1;\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) throws Exception {\n",
    "        Configuration conf = new Configuration();\n",
    "        System.exit(ToolRunner.run(conf, new GroupDriver(), args));\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create an Oozie workflow file</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"code-font\">workflow.xml</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load /YOUR_PATH/oozie-project/workflow.xml\n",
    "<workflow-app xmlns=\"uri:oozie:workflow:0.2\" name=\"map-reduce-job-flow\">\n",
    "    <start to=\"mr-avg-rating\"/>\n",
    "    <action name=\"mr-avg-rating\">\n",
    "        <map-reduce>\n",
    "            <job-tracker>${jobTracker}</job-tracker>\n",
    "            <name-node>${nameNode}</name-node>\n",
    "            <prepare>\n",
    "                <delete path=\"/user/jobflow/temp_avg\"/>\n",
    "            </prepare>\n",
    "            <configuration>\n",
    "                <property>\n",
    "                    <name>mapred.mapper.new-api</name>\n",
    "                    <value>true</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapred.reducer.new-api</name>\n",
    "                    <value>true</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapreduce.job.map.class</name>\n",
    "                    <value>edu.classes.mapreduce.ProdAvgMapper</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapreduce.job.combine.class</name>\n",
    "                    <value>edu.classes.mapreduce.ProdAvgCombiner</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapreduce.job.reduce.class</name>\n",
    "                    <value>edu.classes.mapreduce.ProdAvgReducer</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapreduce.input.fileinputformat.inputdir</name>\n",
    "                    <value>/user/hadoop/reviews_Electronics_5.json</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapreduce.output.fileoutputformat.outputdir</name>\n",
    "                    <value>/user/jobflow/temp_avg</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapreduce.job.output.key.class</name>\n",
    "                    <value>org.apache.hadoop.io.Text</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapreduce.job.output.value.class</name>\n",
    "                    <value>edu.classes.mapreduce.SumCountWritable</value>\n",
    "                </property>\n",
    "            </configuration>\n",
    "        </map-reduce>\n",
    "        <ok to=\"mr-group-rating\"/>\n",
    "        <error to=\"fail\"/>\n",
    "    </action>\n",
    "    <action name=\"mr-group-rating\">\n",
    "        <map-reduce>\n",
    "            <job-tracker>${jobTracker}</job-tracker>\n",
    "            <name-node>${nameNode}</name-node>\n",
    "            <prepare>\n",
    "                <delete path=\"/user/jobflow/output\"/>\n",
    "            </prepare>\n",
    "            <configuration>\n",
    "                <property>\n",
    "                    <name>mapred.mapper.new-api</name>\n",
    "                    <value>true</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapred.reducer.new-api</name>\n",
    "                    <value>true</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapreduce.job.map.class</name>\n",
    "                    <value>edu.classes.mrjobflow.GroupMapper</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapreduce.job.combine.class</name>\n",
    "                    <value>edu.classes.mrjobflow.GroupReducer</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapreduce.job.reduce.class</name>\n",
    "                    <value>edu.classes.mrjobflow.GroupReducer</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapreduce.input.fileinputformat.inputdir</name>\n",
    "                    <value>/user/jobflow/temp_avg</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapreduce.output.fileoutputformat.outputdir</name>\n",
    "                    <value>/user/jobflow/output</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapreduce.job.output.key.class</name>\n",
    "                    <value>org.apache.hadoop.io.IntWritable</value>\n",
    "                </property>\n",
    "                <property>\n",
    "                    <name>mapreduce.job.output.value.class</name>\n",
    "                    <value>org.apache.hadoop.io.IntWritable</value>\n",
    "                </property>\n",
    "            </configuration>\n",
    "        </map-reduce>\n",
    "        <ok to=\"end\"/>\n",
    "        <error to=\"fail\"/>\n",
    "    </action>\n",
    "    <kill name=\"fail\">\n",
    "        <message>Map/Reduce failed, error message[${wf:errorMessage(wf:lastErrorNode())}]</message>\n",
    "    </kill>\n",
    "    <end name=\"end\"/>\n",
    "</workflow-app>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"code-font\">flow.properties</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load /YOUR_PATH/oozie-project/flow.properties\n",
    "nameNode=hdfs://<change>\n",
    "jobTracker=<change>\n",
    "oozie.wf.application.path=${nameNode}/user/hadoop/oozie-app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Running an EMR cluster</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-info\">\n",
    "  <div class=\"msg-text-info\">\n",
    "      <p>1) find out your subnet where a cluster will be run</p>\n",
    "      <p class=\"code-block code-font\">aws ec2 <span class=\"code-key\">describe-subnets</span></p>\n",
    "      <p>2) create a S3 bucket (if needed)</p>\n",
    "      <p class=\"code-block code-font\">aws s3 <span class=\"code-key\">mb</span> s3://YOUR_BUCKET/</p>\n",
    "      <p>3) copy a file with bootstrap actions and your bucket name to S3</p>\n",
    "      <p class=\"code-block code-font\">aws s3 <span class=\"code-key\">cp</span> /YOUR_PATH/config/download-unzip-s3.sh s3://YOUR_BUCKET/scripts/download-unzip-s3.sh</p>\n",
    "      <p>4) copy oozie workflow files to S3</p>\n",
    "      <p class=\"code-block code-font\">aws s3 <span class=\"code-key\">cp</span> /YOUR_PATH/oozie-project s3://YOUR_BUCKET/oozie --recursive</p>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Launch an EMR cluster</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws emr create-cluster \\\n",
    "    --name \"Hadoop_Cluster\" \\\n",
    "    --release-label emr-5.8.0 \\\n",
    "    --applications Name=Hadoop Name=Zeppelin Name=Oozie \\\n",
    "    --log-uri s3://aws-emr-logs/logs/ \\\n",
    "    --service-role emr-default-role \\\n",
    "    --instance-groups InstanceGroupType=MASTER,InstanceCount=1,InstanceType=m4.large InstanceGroupType=CORE,InstanceCount=3,InstanceType=m4.large \\\n",
    "    --ec2-attributes InstanceProfile=emr-default-ec2-role,KeyName=BigData_Keys,SubnetId=YOUR_SUBNET \\\n",
    "    --bootstrap-action Path=s3://YOUR_BUCKET/scripts/download-unzip-s3.sh \\\n",
    "    --configurations file:///YOUR_PATH/config/hdfs-config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Check a state of your cluster</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!aws emr describe-cluster \\\n",
    "    --cluster-id YOUR_CLUSTER_ID \\\n",
    "    --query \"Cluster.Status\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Set up an SSH tunnel using dynamic port forwarding (run in your terminal)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sudo aws emr socks --cluster-id YOUR_CLUSTER_ID --key-pair-file /YOUR_PATH/bigdata_keys.pem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-ref\">\n",
    "      <div class=\"msg-text-ref\">\n",
    "          <p>To connect to hadoop web dashboards, see the following guides: <br>\n",
    "          <a href=\"http://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-ssh-tunnel.html\">Part 1: Set Up an SSH Tunnel to the Master Node Using Dynamic Port Forwarding</a><br>\n",
    "          <a href=\"http://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-connect-master-node-proxy.html\">Part 2: Configure Proxy Settings to View Websites Hosted on the Master Node</a>\n",
    "          </p>\n",
    "     </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Print out an internal host name of the master node</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!aws emr list-instances \\\n",
    "        --cluster-id YOUR_CLUSTER_ID \\\n",
    "        --instance-group-types \"MASTER\" \\\n",
    "        --query \"Instances[0].PrivateDnsName\" \\\n",
    "        --output text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>Use the hostname to connect to hadoop web dashboards. For exmpale,</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"code-block code-font\" href=\"http://ip-10-0-1-14.eu-west-1.compute.internal:8088\">ip-10-0-1-14.eu-west-1.compute.internal:8088</a> (ResourceManager dashboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Connect to the master node via SSH</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>1. Display a public ip of the master</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!aws emr list-instances \\\n",
    "        --cluster-id YOUR_CLUSTER_ID \\\n",
    "        --instance-group-types \"MASTER\" \\\n",
    "        --query \"Instances[0].PublicIpAddress\" \\\n",
    "        --output text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>2. In your terminal run the following command</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo ssh -i /YOUR_PATH/bigdata_keys.pem hadoop@MASTER_PUBLIC_IP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>On the master node run the command below to copy the <span class=\"code-font\">reviews_Electronics_5.json</span> file from S3 to HDFS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoop distcp s3://YOUR_BUCKET/data/reviews_Electronics_5.json hdfs:///user/hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Running an Oozie workflow</b> (all commands on the master node)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Copy the <span class=\"code-font\">flow.properties</span> file from S3 to a local directory of the master node</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo aws s3 cp s3://YOUR_BUCKET/oozie/flow.properties /home/hadoop/oozie/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Insert to the first line of the file a host name of the master using the following command</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo sed -i \"1imasterNode=$HOSTNAME\" /home/hadoop/oozie/flow.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create a directory in HDFS to upload jar files and an oozie workflow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -mkdir -p /user/hadoop/oozie-app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Copy the <span class=\"code-font\">workflow.xml</span> file to HDFS</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -cp s3://YOUR_BUCKET/oozie/workflow.xml /user/hadoop/oozie-app/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Copy the jar files to HDFS</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -cp s3://YOUR_BUCKET/oozie/lib /user/hadoop/oozie-app/lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Run the workflow. You can use the ResourceManager dashboard to track execution</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oozie job -config /home/hadoop/oozie/flow.properties -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Run the following command to see status of jobs in your workflow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oozie job -info YOUR_JOB_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Look at logs using the command below</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oozie job -log YOUR_JOB_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-info\">\n",
    "  <div class=\"msg-text-info\">\n",
    "      <p>Oozie log files youn find here</p>\n",
    "      <p class=\"code-block code-font\"><span class=\"code-key\">ls</span> /var/log/oozie</p>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Display the result of computation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -cat /user/jobflow/output/part-r-0000*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-imp\">\n",
    "  <div class=\"msg-text-imp\"><p>\n",
    "      Don't forget to terminate the cluster, otherwise your free subscription runs out quickly. A rule of thumb is that you terminate the cluster after all job is completed. There are two options to do this:<br>\n",
    "      1) <span class=\"code-font\">EMR -> Select Cluster -> Terminate</span><br>\n",
    "      2) AWS CLI: <span class=\"code-font\">aws emr terminate-clusters --cluster-ids j-xxxxx</span>\n",
    "      \n",
    "  </p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Terminate the cluster</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!aws emr terminate-clusters --cluster-ids YOUR_CLUSTER_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Check that all clusters are terminated</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!aws emr list-clusters --active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1c\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            c. Tez\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#1b\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">2. Data Serialization Systems</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To Content</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2a\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            a. Java\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2b\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2b\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            b. Avro\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2a\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2c\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2c\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            c. Parquet\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2b\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#3\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">3. References</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To content</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JobControl\n",
    "<ul>\n",
    "    <li><a href=\"https://hadoop.apache.org/docs/r2.7.2/api/org/apache/hadoop/mapreduce/lib/jobcontrol/JobControl.html\">JobControl</a></li>\n",
    "    <li><a  href=\"https://hadoop.apache.org/docs/r2.7.2/api/org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.html\">ControlledJob</a></li>\n",
    "    <li><a href=\"http://coe4bd.github.io/HadoopHowTo/multipleJobsSingle/multipleJobsSingle.html\">Chaining and Managing Multiple MapReduce Jobs with One Driver</a></li>\n",
    "    <li><a href=\"https://www.programcreek.com/java-api-examples/index.php?source_dir=HadoopEKG-master/mapred/src/benchmarks/gridmix2/src/java/org/apache/hadoop/mapreduce/GridMixRunner.java\">GridMixRunner.java</a></li>\n",
    "</ul>\n",
    "\n",
    "Oozie\n",
    "<ul>\n",
    "    <li><a href=\"https://oozie.apache.org/docs/4.3.0/\">Oozie, Workflow Engine for Apache Hadoop</a></li>\n",
    "    <li><a href=\"https://www.safaribooksonline.com/library/view/apache-oozie/9781449369910/ch04.html\">Apache Oozie by Aravind Srinivasan, Mohammad Kamrul Islam</a></li>\n",
    "    <li><a href=\"https://cwiki.apache.org/confluence/display/OOZIE/Map+Reduce+Cookbook\">Map Reduce Cookbook</a></li>\n",
    "    <li><a href=\"https://aws.amazon.com/ru/blogs/big-data/run-common-data-science-packages-on-anaconda-and-oozie-with-amazon-emr/\">Run Common Data Science Packages on Anaconda and Oozie with Amazon EMR</a></li>\n",
    "    <li><a href=\"https://aws.amazon.com/blogs/big-data/use-apache-oozie-workflows-to-automate-apache-spark-jobs-and-more-on-amazon-emr/\">Use Apache Oozie Workflows to Automate Apache Spark Jobs (and more!) on Amazon EMR</a></li>\n",
    "    <li><a href=\"https://discuss.pivotal.io/hc/en-us/articles/203355837-How-to-run-a-MapReduce-jar-using-Oozie-workflow\">How to run a MapReduce jar using Oozie workflow</a></li>\n",
    "    <li><a href=\"https://gist.github.com/airawat/6001806\">Oozie Workflow Java MapReduce Action</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
