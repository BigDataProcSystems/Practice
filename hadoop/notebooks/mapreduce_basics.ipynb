{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\"><b>Introduction to </b> <span style=\"font-weight:bold; color:green\">MapReduce</span></div><hr>\n",
    "<div style=\"text-align:right;\">Sergei Yu. Papulin <span style=\"font-style: italic;font-weight: bold;\">(papulin_bmstu@mail.ru, papulin_hse@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"0\"></a>\n",
    "<div><span style=\"font-size:14pt; font-weight:bold\">Content</span>\n",
    "    <ol>\n",
    "        <li><a href=\"#1\">Word Count</a>\n",
    "            <ol style = \"list-style-type:lower-alpha\">\n",
    "                <li><a href=\"#1a\">Java</a></li>\n",
    "                <li><a href=\"#1b\">Python</a></li>\n",
    "                <li><a href=\"#1c\">Scala</a></li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><a href=\"#2\">Average Rating Calculation</a>\n",
    "            <ol style = \"list-style-type:lower-alpha\">\n",
    "                <li><a href=\"#2a\">Average ratings for each product</a></li>\n",
    "                <li><a href=\"#2b\">Average rating of all products</a></li>\n",
    "                <li><a href=\"#2c\">Filter items by their ratings</a></li>\n",
    "                <li><a href=\"#2d\">Average rating of product</a></li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><a href=\"#3\">MapReduce on AWS EMR</a></li>\n",
    "        <li><a href=\"#4\">References</a></li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Launch the cell below to apply a jupyter notebook style</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href=\"css/style.css\" rel=\"stylesheet\" type=\"text/css\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<link href=\"css/style.css\" rel=\"stylesheet\" type=\"text/css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">1. MapReduce Word Count</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To Content</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1a\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            a. Java\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#1\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#1b\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Run and debug a MapReduce code in IntelliJ IDE</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>MapReduce with Java</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-info\">\n",
    "      <div class=\"msg-text-info\">\n",
    "          <p>MapReduce Tutorial with the word count example is <a href=\"https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html\">here</a></p>\n",
    "     </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import java.io.IOException;\n",
    "import java.util.StringTokenizer;\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Job;\n",
    "import org.apache.hadoop.mapreduce.Mapper;\n",
    "import org.apache.hadoop.mapreduce.Reducer;\n",
    "import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n",
    "import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n",
    "\n",
    "public class WordCount {\n",
    "\n",
    "  public static class TokenizerMapper\n",
    "       extends Mapper<Object, Text, Text, IntWritable>{\n",
    "\n",
    "    private final static IntWritable one = new IntWritable(1);\n",
    "    private Text word = new Text();\n",
    "\n",
    "    public void map(Object key, Text value, Context context\n",
    "                    ) throws IOException, InterruptedException {\n",
    "      StringTokenizer itr = new StringTokenizer(value.toString());\n",
    "      while (itr.hasMoreTokens()) {\n",
    "        word.set(itr.nextToken());\n",
    "        context.write(word, one);\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  public static class IntSumReducer\n",
    "       extends Reducer<Text,IntWritable,Text,IntWritable> {\n",
    "    private IntWritable result = new IntWritable();\n",
    "\n",
    "    public void reduce(Text key, Iterable<IntWritable> values,\n",
    "                       Context context\n",
    "                       ) throws IOException, InterruptedException {\n",
    "      int sum = 0;\n",
    "      for (IntWritable val : values) {\n",
    "        sum += val.get();\n",
    "      }\n",
    "      result.set(sum);\n",
    "      context.write(key, result);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  public static void main(String[] args) throws Exception {\n",
    "    Configuration conf = new Configuration();\n",
    "    Job job = Job.getInstance(conf, \"word count\");\n",
    "    job.setJarByClass(WordCount.class);\n",
    "    job.setMapperClass(TokenizerMapper.class);\n",
    "    job.setCombinerClass(IntSumReducer.class);\n",
    "    job.setReducerClass(IntSumReducer.class);\n",
    "    job.setOutputKeyClass(Text.class);\n",
    "    job.setOutputValueClass(IntWritable.class);\n",
    "    FileInputFormat.addInputPath(job, new Path(args[0]));\n",
    "    FileOutputFormat.setOutputPath(job, new Path(args[1]));\n",
    "    System.exit(job.waitForCompletion(true) ? 0 : 1);\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"cmd-no-code\"></span>Run the code</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Run on the Local Cloudera VM</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"cmd-no-code\"></span>Create a jar file</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Copy the jar file</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo scp -P 2222 /YOUR_PATH/WordCount.jar cloudera@127.0.0.1:/home/cloudera/classes/mapreduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Copy the <span class=\"code-font\">\"/data/samples.json\"</span> file to your Local Cloudera VM</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo scp -P 2222 /YOUR_PATH/samples.json cloudera@127.0.0.1:/home/cloudera/classes/mapreduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Use port forwarding from your local host to the local VM to access a HDFS dashboard</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo ssh -N -f -L 9962:quickstart.cloudera:8088 cloudera@127.0.0.1 -p 2222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Open a web browser to see a Hadoop dashboard</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"code-block code-font\"><a href=\"http://localhost:9962\">http://localhost:9962</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Connect to the VM via SSH</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo ssh -p 2222 cloudera@127.0.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create a HDFS directory for the extracted data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -mkdir -p /mapreduce_data/input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Move the data to the HDFS directory</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -moveFromLocal \\\n",
    "            /home/cloudera/classes/mapreduce/samples.json \\\n",
    "            hdfs:///mapreduce_data/input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Run the jar file</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoop jar /home/cloudera/classes/mapreduce/WordCount.jar \\\n",
    "            hdfs:///mapreduce_data/input \\\n",
    "            hdfs:///mapreduce_data/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Display content of output files</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -cat /mapreduce_data/output/part-r-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Remove the output directory if needed</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -rm -r /mapreduce_data/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1b\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            b. Python\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#1a\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#1c\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Run and debug a MapReduce code</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Assign paths to python files with map and reduce functions, and data source</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_python_file = \"/YOUR_PATH/code_py/wordcount_mapper.py\"\n",
    "reduce_python_file = \"/YOUR_PATH/code_py/wordcount_reduce.py\"\n",
    "\n",
    "data = \"/YOUR_PATH/data/samples.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Map function</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $map_python_file\n",
    "import sys\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line = line.split()\n",
    "    for key in line:\n",
    "        value = 1\n",
    "        print('%s\\t%i' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Reduce function</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile $reduce_python_file\n",
    "import sys\n",
    "\n",
    "last_key = None\n",
    "running_total = 0\n",
    "\n",
    "for input_line in sys.stdin:\n",
    "    input_line = input_line.strip()\n",
    "    this_key, value = input_line.split(\"\\t\", 1)\n",
    "    value = int(value)\n",
    "    \n",
    "    if last_key == this_key:\n",
    "        running_total += value\n",
    "    else:\n",
    "        if last_key:\n",
    "            print(\"%s\\t%i\" % (last_key, running_total))\n",
    "    \n",
    "        running_total = value\n",
    "        last_key = this_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Load a python code of a map function to the notebook</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load $map_python_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Load a python code of a reduce function to the notebook</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load $reduce_python_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Examining results of map and reduce functions without Hadoop</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Test a map function</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $data | python $map_python_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Test map and reduce functions together</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $data | python $map_python_file | sort | python $reduce_python_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Examining results of map and reduce functions on the Local Cloudera VM</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \\\n",
    "    -D mapreduce.job.reduces=2 \\\n",
    "    -mapper \"python $map_python_file\" \\\n",
    "    -reducer \"python $reduce_python_file\" \\\n",
    "    -input \"/mapreduce_data/input\" \\\n",
    "    -output \"/mapreduce_data/output2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1c\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            c. Scala\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#1b\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">2. Average Rating Calculation</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To Content</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2a\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            a. Average ratings for each product\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2b\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Run and debug a source code</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"code-font\">ProdAvgDriver.java</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.mapreduce;\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.conf.Configured;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Job;\n",
    "import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n",
    "import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n",
    "import org.apache.hadoop.util.Tool;\n",
    "import org.apache.hadoop.util.ToolRunner;\n",
    "\n",
    "public class ProdAvgDriver extends Configured implements Tool {\n",
    "\n",
    "    public int run(String[] args) throws Exception {\n",
    "\n",
    "        Job job = Job.getInstance(getConf(), \"ProdAverageRating\");\n",
    "        job.setJarByClass(ProdAvgDriver.class);\n",
    "        job.setMapperClass(ProdAvgMapper.class);\n",
    "        job.setCombinerClass(ProdAvgCombiner.class);\n",
    "        job.setReducerClass(ProdAvgReducer.class);\n",
    "        job.setOutputKeyClass(Text.class);\n",
    "        job.setOutputValueClass(SumCountWritable.class);\n",
    "        FileInputFormat.addInputPath(job, new Path(args[0]));\n",
    "        FileOutputFormat.setOutputPath(job, new Path(args[1]));\n",
    "        return job.waitForCompletion(true) ? 0 : 1;\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) throws Exception {\n",
    "        Configuration conf = new Configuration();\n",
    "        System.exit(ToolRunner.run(conf, new ProdAvgDriver(), args));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"code-font\">SumCountWritable.java</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.mapreduce;\n",
    "\n",
    "import org.apache.hadoop.io.Writable;\n",
    "\n",
    "import java.io.DataInput;\n",
    "import java.io.DataOutput;\n",
    "import java.io.IOException;\n",
    "\n",
    "public class SumCountWritable implements Writable {\n",
    "\n",
    "    SumCountWritable() {\n",
    "        this.sum = 0d;\n",
    "        this.count = 0;\n",
    "    }\n",
    "\n",
    "    SumCountWritable(double sum, int count){\n",
    "        this.sum = sum;\n",
    "        this.count = count;\n",
    "    }\n",
    "\n",
    "    private double sum;\n",
    "    private int count;\n",
    "\n",
    "    public void set(double sum, int count) {\n",
    "        this.sum = sum;\n",
    "        this.count = count;\n",
    "    }\n",
    "\n",
    "    public double getSum() {\n",
    "        return this.sum;\n",
    "    }\n",
    "\n",
    "    public int getCount() {\n",
    "        return this.count;\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    public void write(DataOutput out) throws IOException {\n",
    "        out.writeDouble(this.sum);\n",
    "        out.writeInt(this.count);\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    public void readFields(DataInput in) throws IOException {\n",
    "        this.sum = in.readDouble();\n",
    "        this.count = in.readInt();\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    public String toString() {\n",
    "        return this.sum + \":\" + this.count;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"code-font\">ProdAvgMapper.java</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.mapreduce;\n",
    "\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Mapper;\n",
    "import org.json.JSONObject;\n",
    "\n",
    "import java.io.IOException;\n",
    "\n",
    "public class ProdAvgMapper extends Mapper<Object, Text, Text, SumCountWritable> {\n",
    "\n",
    "    private Text word = new Text();\n",
    "\n",
    "    public void map(Object key, Text value, Context context\n",
    "    ) throws IOException, InterruptedException {\n",
    "\n",
    "        JSONObject json = new JSONObject(value.toString());\n",
    "\n",
    "        String prod = json.getString(\"asin\");\n",
    "        double rating = json.getDouble(\"overall\");\n",
    "\n",
    "        //System.out.println(rating);\n",
    "\n",
    "        context.write(new Text(prod), new SumCountWritable(rating, 1));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"code-font\">ProdAvgCombiner.java</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.mapreduce;\n",
    "\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Reducer;\n",
    "\n",
    "import java.io.IOException;\n",
    "\n",
    "public class ProdAvgCombiner extends Reducer<Text,SumCountWritable,Text,SumCountWritable> {\n",
    "\n",
    "    private SumCountWritable result = new SumCountWritable();\n",
    "\n",
    "    public void reduce(Text key, Iterable<SumCountWritable> values, Context context)\n",
    "            throws IOException, InterruptedException {\n",
    "\n",
    "        double sum = 0.0;\n",
    "        int count = 0;\n",
    "\n",
    "        for (SumCountWritable val : values) {\n",
    "            sum += val.getSum();\n",
    "            count += val.getCount();\n",
    "        }\n",
    "\n",
    "        result.set(sum, count);\n",
    "\n",
    "        //System.out.println(\"Combiner\");\n",
    "        //System.out.println(result.toString());\n",
    "\n",
    "        context.write(key, result);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"code-font\">ProdAvgReducer.java</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.mapreduce;\n",
    "\n",
    "import org.apache.hadoop.io.DoubleWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Reducer;\n",
    "\n",
    "import java.io.IOException;\n",
    "\n",
    "public class ProdAvgReducer extends Reducer<Text,SumCountWritable,Text,DoubleWritable> {\n",
    "\n",
    "    private SumCountWritable result = new SumCountWritable();\n",
    "\n",
    "    public void reduce(Text key, Iterable<SumCountWritable> values, Context context)\n",
    "            throws IOException, InterruptedException {\n",
    "\n",
    "        double sum = 0.0;\n",
    "        int count = 0;\n",
    "\n",
    "        for (SumCountWritable val : values) {\n",
    "            sum += val.getSum();\n",
    "            count += val.getCount();\n",
    "        }\n",
    "\n",
    "        result.set(sum, count);\n",
    "\n",
    "        //System.out.println(\"Reducer\");\n",
    "        //System.out.println(result.toString());\n",
    "\n",
    "        double average = sum / count;\n",
    "\n",
    "        System.out.println(key + \" : \" + average);\n",
    "\n",
    "        context.write(key, new DoubleWritable(average));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"cmd-no-code\"></span>Run the code. Use the <span class=\"code-font\">\"samples_100.json\"</span> as the input</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"cmd-no-code\"></span>Create a jar file</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Run on the Local Cloudera VM</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"cmd-no-code\"></span>Download an archive of data using <span class=\"code-font\">wget</span> to your Local Cloudera VM, extract them, and upload to the HDFS.<br>\n",
    "Link to dataset: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-info\">\n",
    "  <div class=\"msg-text-info\"><p>For more information about this dataset click on the link below<br><a href=\"http://jmcauley.ucsd.edu/data/amazon/\">Amazon product data</a></p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create a HDFS directory for the extracted data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -mkdir -p /mapreduce_data/input_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Copy the jar file (if needed)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo scp -P 2222 /YOUR_PATH/ProdAvgRatingApp.jar cloudera@127.0.0.1:/home/cloudera/classes/mapreduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Copy an archive with data to the VM (or use gwet for download the file from the Internet)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo scp -P 2222 /YOUR_PATH/reviews_Electronics_5.json.gz cloudera@127.0.0.1:/home/cloudera/classes/mapreduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Use port forwarding from your local host to the local VM to access a HDFS dashboard</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo ssh -N -f -L 9962:quickstart.cloudera:8088 cloudera@127.0.0.1 -p 2222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Open a web browser to see a Hadoop dashboard</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"code-block code-font\"><a href=\"http://localhost:9962\">http://localhost:9962</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Connect to the VM via SSH</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo ssh -p 2222 cloudera@127.0.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Extract data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gzip -d /YOUR_PATH/reviews_Electronics_5.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create a HDFS directory for the extracted data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -mkdir -p /mapreduce_data/input_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Move the data to the HDFS directory</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -moveFromLocal \\\n",
    "            /home/cloudera/classes/mapreduce/reviews_Electronics_5.json \\\n",
    "            hdfs:///mapreduce_data/input_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Run the jar file</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoop jar /home/cloudera/classes/mapreduce/ProdAvgRatingApp.jar \\\n",
    "            hdfs:///mapreduce_data/input_ratings \\\n",
    "            hdfs:///mapreduce_data/output_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoop jar /home/cloudera/classes/mapreduce/ProdAvgRatingApp.jar hdfs:///mapreduce_data/input_ratings hdfs:///mapreduce_data/output_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Display content of output files</p>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -cat /mapreduce_data/output_ratings/part-r-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Remove the output directory (if needed)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -rm -r /mapreduce_data/output_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2b\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            b. Average rating of all products\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2a\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2c\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Run and debug a source code</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"code-font\">AverageDriver.java</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.mapreduce;\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.conf.Configured;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.mapreduce.Job;\n",
    "import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n",
    "import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n",
    "import org.apache.hadoop.util.Tool;\n",
    "import org.apache.hadoop.util.ToolRunner;\n",
    "\n",
    "public class AverageDriver extends Configured implements Tool {\n",
    "\n",
    "    public int run(String[] args) throws Exception {\n",
    "\n",
    "        Job job = Job.getInstance(getConf(), \"AverageRating\");\n",
    "        job.setJarByClass(AverageDriver.class);\n",
    "        job.setMapperClass(AverageMapper.class);\n",
    "        job.setCombinerClass(AverageCombiner.class);\n",
    "        job.setReducerClass(AverageReducer.class);\n",
    "        job.setOutputKeyClass(IntWritable.class);\n",
    "        job.setOutputValueClass(SumCountWritable.class);\n",
    "        FileInputFormat.addInputPath(job, new Path(args[0]));\n",
    "        FileOutputFormat.setOutputPath(job, new Path(args[1]));\n",
    "        return job.waitForCompletion(true) ? 0 : 1;\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) throws Exception {\n",
    "        Configuration conf = new Configuration();\n",
    "        System.exit(ToolRunner.run(conf, new AverageDriver(), args));\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"code-font\">AverageMapper.java</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.mapreduce;\n",
    "\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Mapper;\n",
    "import org.json.JSONObject;\n",
    "\n",
    "import java.io.IOException;\n",
    "\n",
    "public class AverageMapper extends Mapper<Object, Text, IntWritable, SumCountWritable> {\n",
    "\n",
    "    private final static IntWritable one = new IntWritable(1);\n",
    "    private Text word = new Text();\n",
    "\n",
    "    public void map(Object key, Text value, Context context\n",
    "    ) throws IOException, InterruptedException {\n",
    "\n",
    "        JSONObject json = new JSONObject(value.toString());\n",
    "\n",
    "        double rating = json.getDouble(\"overall\");\n",
    "\n",
    "        //System.out.println(rating);\n",
    "\n",
    "        context.write(one, new SumCountWritable(rating, 1));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"code-font\">AverageCombiner.java</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.mapreduce;\n",
    "\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.mapreduce.Reducer;\n",
    "\n",
    "import java.io.IOException;\n",
    "\n",
    "public class AverageCombiner extends Reducer<IntWritable,SumCountWritable,IntWritable,SumCountWritable> {\n",
    "\n",
    "    private SumCountWritable result = new SumCountWritable();\n",
    "\n",
    "    public void reduce(IntWritable key, Iterable<SumCountWritable> values,Context context)\n",
    "            throws IOException, InterruptedException {\n",
    "\n",
    "        double sum = 0.0;\n",
    "        int count = 0;\n",
    "        for (SumCountWritable val : values) {\n",
    "            sum += val.getSum();\n",
    "            count += val.getCount();\n",
    "        }\n",
    "\n",
    "        result.set(sum, count);\n",
    "\n",
    "        //System.out.println(\"Combiner\");\n",
    "        //System.out.println(result.toString());\n",
    "\n",
    "        context.write(key, result);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"code-font\">AverageReducer.java</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.mapreduce;\n",
    "\n",
    "import org.apache.hadoop.io.DoubleWritable;\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Reducer;\n",
    "\n",
    "import java.io.IOException;\n",
    "\n",
    "public class AverageReducer extends Reducer<IntWritable,SumCountWritable,Text,DoubleWritable> {\n",
    "\n",
    "    private SumCountWritable result = new SumCountWritable();\n",
    "\n",
    "    public void reduce(IntWritable key, Iterable<SumCountWritable> values, Context context)\n",
    "            throws IOException, InterruptedException {\n",
    "\n",
    "        double sum = 0.0;\n",
    "        int count = 0;\n",
    "\n",
    "        for (SumCountWritable val : values) {\n",
    "            sum += val.getSum();\n",
    "            count += val.getCount();\n",
    "        }\n",
    "\n",
    "        result.set(sum, count);\n",
    "\n",
    "        //System.out.println(\"Reducer\");\n",
    "        //System.out.println(result.toString());\n",
    "\n",
    "        double average = sum / count;\n",
    "\n",
    "        System.out.println(average);\n",
    "\n",
    "        context.write(new Text(\"Average\"), new DoubleWritable(average));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-task\">\n",
    "  <div class=\"msg-text-task\"><p>Run on the Local Cloudera VM</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR INSTRUCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2c\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            c. Filter items by their ratings\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2b\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2d\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Run and debug a source code</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"code-font\">FilterDriver.java</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.mapreduce;\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.conf.Configured;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Job;\n",
    "import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n",
    "import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;\n",
    "import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n",
    "import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;\n",
    "import org.apache.hadoop.util.Tool;\n",
    "import org.apache.hadoop.util.ToolRunner;\n",
    "\n",
    "public class FilterDriver extends Configured implements Tool {\n",
    "\n",
    "    public int run(String[] args) throws Exception {\n",
    "\n",
    "        Job job = Job.getInstance(getConf(), \"FIlterByRating\");\n",
    "\n",
    "        job.setJarByClass(FilterDriver.class);\n",
    "        job.setMapperClass(FilterMapper.class);\n",
    "\n",
    "        job.setNumReduceTasks(0);\n",
    "\n",
    "        job.setInputFormatClass(TextInputFormat.class);\n",
    "        job.setOutputFormatClass(TextOutputFormat.class);\n",
    "\n",
    "        job.setOutputKeyClass(IntWritable.class);\n",
    "        job.setOutputValueClass(Text.class);\n",
    "\n",
    "        FileInputFormat.addInputPath(job, new Path(args[0]));\n",
    "        FileOutputFormat.setOutputPath(job, new Path(args[1]));\n",
    "\n",
    "        return job.waitForCompletion(true) ? 0 : 1;\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) throws Exception {\n",
    "        Configuration conf = new Configuration();\n",
    "\n",
    "        conf.setInt(\"threshold\", Integer.valueOf(args[2]));\n",
    "\n",
    "        System.exit(ToolRunner.run(conf, new RatingDriver(), args));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span class=\"code-font\">FilterMapper.java</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.mapreduce;\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Mapper;\n",
    "import org.json.JSONObject;\n",
    "\n",
    "import java.io.IOException;\n",
    "\n",
    "public class FilterMapper extends Mapper<Object, Text, IntWritable, Text> {\n",
    "\n",
    "    private final static IntWritable one = new IntWritable(1);\n",
    "    private Text word = new Text();\n",
    "    private int thld = 0;\n",
    "\n",
    "    protected void setup(Context context) throws IOException, InterruptedException {\n",
    "\n",
    "        Configuration conf = context.getConfiguration();\n",
    "\n",
    "        thld = conf.getInt(\"threshold\", 0);\n",
    "\n",
    "    }\n",
    "\n",
    "    public void map(Object key, Text value, Context context) throws IOException, InterruptedException {\n",
    "\n",
    "        JSONObject json = new JSONObject(value.toString());\n",
    "\n",
    "        double rating = json.getDouble(\"overall\");\n",
    "\n",
    "        if (rating >= thld) {\n",
    "\n",
    "            //System.out.println(rating);\n",
    "            context.write(one, new Text(value.toString()));\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-task\">\n",
    "  <div class=\"msg-text-task\"><p>Run on the Local Cloudera VM</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR INSTRUCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2d\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            d. Average rating of product\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2c\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#3\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-task\">\n",
    "  <div class=\"msg-text-task\"><p>Write a code for computing average ratings per years for a given product id</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE AND INSTRUCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">3. MapReduce on AWS EMR\n",
    "</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To Content</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-task\">\n",
    "  <div class=\"msg-text-task\"><p>Deploy an EMR cluser with 3 instances and run the apps from the previous section. Use <span class=\"code-font\">reviews_Electronics_5.json</span> as input after uploading it to the HDFS</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-info\">\n",
    "  <div class=\"msg-text-info\"><p>By default for this configuration a replication factor for HDFS will be set to 1 by EMR. You can you the <span class=\"code-font\">--configurations</span> option for the <span class=\"code-font\">create-cluster</span> command to assign your configuration. To replace a replication factor with 3, specify a configuration from the <span class=\"code-font\">hdfs_config.json</span> file that is in the <span class=\"code-font\">config</span> directory</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR INSTRUCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name=\"4\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">4. References</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To content</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
