{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\"><b>Introduction to </b> <span style=\"font-weight:bold; color:green\">HDFS</span></div><hr>\n",
    "<div style=\"text-align:right;\">Sergei Yu. Papulin <span style=\"font-style: italic;font-weight: bold;\">(papulin_bmstu@mail.ru, papulin_hse@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"0\"></a>\n",
    "<div><span style=\"font-size:14pt; font-weight:bold\">Content</span>\n",
    "    <ol>\n",
    "        <li><a href=\"#1\">HDFS Shell Commands</a></li>\n",
    "        <li><a href=\"#2\">HDFS Java API</a>\n",
    "            <ol style = \"list-style-type:lower-alpha\">\n",
    "                <li><a href=\"#2a\">Reading Files</a></li>\n",
    "                <li><a href=\"#2b\">Copying Files From Local To HDFS</a></li>\n",
    "                <li><a href=\"#2c\">Other manipulations</a></li>\n",
    "                <li><a href=\"#2d\">Running on Cloudera</a></li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><a href=\"#3\">HDFS on EMR Cluster</a></li>\n",
    "        <li><a href=\"#4\">References</a></li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Launch the cell below to apply a jupyter notebook style</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href=\"css/style.css\" rel=\"stylesheet\" type=\"text/css\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<link href=\"css/style.css\" rel=\"stylesheet\" type=\"text/css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">1. HDFS Shell Commands</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To content</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Basic Commands</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-info\">\n",
    "      <div class=\"msg-text-info\">\n",
    "          <p><a href=\"https://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/FileSystemShell.html\">The File System (FS) shell</a></p>\n",
    "     </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Connect to your local cloudera via SSH</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Show HDFS topology</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfsadmin -printTopology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-info\">\n",
    "      <div class=\"msg-text-info\">\n",
    "          <p>The cloudera user has all permissions</p>\n",
    "     </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Show a directory</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create a directory in HDFS on behalf of the hdfs user</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo -u hdfs hdfs dfs -mkdir -p /hdfs_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Assign permissions to users in HDFS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo -u hdfs hdfs dfs -chmod -R 777 /data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create a subdirectory</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -mkdir -p /hdfs_data/first_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Copy files from your local file system to the HDFS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -copyFromLocal -f /YOUR_PATH/* /hdfs_data/first_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Check that all data was correctly copied</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -ls /hdfs_data/first_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Show a report about blocks of the file</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs hdfs fsck /hdfs_data/first_data/YOUR_FILE -files -blocks -locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Displays last kilobyte</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -tail /hdfs_data/first_data/YOUR_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>HDFS Dashboard</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Use port forwarding from your local host to the local VM to access a HDFS dashboard</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo ssh -N -f -L 9961:quickstart.cloudera:50070 cloudera@127.0.0.1 -p 2222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Open a web brower to see a HDFS dashboard</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"code-block code-font\"><a href=\"http://localhost:9961\">http://localhost:9961</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">2. HDFS Java API</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To content</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-info\">\n",
    "      <div class=\"msg-text-info\">\n",
    "          <p>It's better to develope apps on a machine where a Hadoop cluster is running in one of the available modes. For example, you can install IntelliJ on the local cloudera VM and develope app there.\n",
    "          </p>\n",
    "     </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-info\">\n",
    "      <div class=\"msg-text-info\">\n",
    "          <p><a href=\"https://hadoop.apache.org/docs/current/api/overview-summary.html\">Current Version of Hadoop API</a>\n",
    "          </p>\n",
    "     </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check a version of your HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Print out a version of your JDK</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-warning\">\n",
    "  <div class=\"msg-text-warn\"><p>Version of JDK on the Cloudera Local VM is 7. So you have to set this version for your projects in the IntelliJ IDE<p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>JDK 7 Installation</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-ref\">\n",
    "  <div class=\"msg-text-ref\"><p>For more information use link below<br><a href=\"http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html\">Java SE 7 Archive Downloads</a><br><a href=\"https://askubuntu.com/questions/920106/webupd8-oracle-java-7-installer-failing-with-404\">webupd8 oracle-java-7-installer failing with 404</a></p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2a\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            a. Reading Files\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2b\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Creating HDFS App jar files in IntelliJ IDE</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IntelliJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://www.jetbrains.com/help/idea/creating-running-and-packaging-your-first-java-application.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create a new project</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "File -> Project -> Java (select appropriate sdk) -> Next -> Project Name: HDFSTest2 -> Finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Attach hadoop dependencies through the Maven</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "File -> Project Structure -> Modules -> Dependencies -> Add -> Library -> From Maven ->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create a new class</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Right Click in scr -> New -> Java Class -> edu.classes.hdfs.MyReadFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "org.apache.hadoop:hadoop-client:2.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-info\">\n",
    "  <div class=\"msg-text-info\"><p>For more information use link below<br><a href=\"https://mrchief2015.wordpress.com/2015/02/09/compiling-and-debugging-hadoop-applications-with-intellij-idea-for-windows/\n",
    "\">HOW-TO: COMPILE AND DEBUG HADOOP APPLICATIONS WITH INTELLIJ IDEA IN WINDOWS OS (64BIT)</a><br><a href=\"https://blog.cloudera.com/blog/2014/06/how-to-create-an-intellij-idea-project-for-apache-hadoop/\">How-to: Create an IntelliJ IDEA Project for Apache Hadoop</a></p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Add the code below to your class file</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Hadoop Definitive Guide \n",
    "\n",
    "package edu.classes.hdfs;\n",
    "\n",
    "import org.apache.hadoop.io.IOUtils;\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.fs.FileSystem;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "\n",
    "import java.io.InputStream;\n",
    "import java.net.URI;\n",
    "\n",
    "public class MyReadFile {\n",
    "\n",
    "    public static void main(String[] args) throws Exception {\n",
    "\n",
    "        String uri = args[0];\n",
    "\n",
    "        Configuration conf = new Configuration();\n",
    "\n",
    "        FileSystem fs = FileSystem.get(URI.create(uri), conf);\n",
    "\n",
    "        InputStream in = null;\n",
    "\n",
    "        try {\n",
    "\n",
    "            in = fs.open(new Path(uri));\n",
    "            IOUtils.copyBytes(in, System.out, 4096, false);\n",
    "        } finally {\n",
    "\n",
    "            IOUtils.closeStream(in);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Edit configurations and run the project</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Run -> Edit configurations -> Add -> Main class: edu.classes.hdfs.MyReadFile; Program arguments: /input -> Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Run -> Run 'configuration name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Build Jar File</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "File -> Project Structure -> Artifacts -> Add -> Jar -> From modules... -> Main Class: edu.classes.hdfs.MyReadFile -> Apply -> Ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Build -> Build Artefacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-ref\">\n",
    "  <div class=\"msg-text-ref\"><p>For more information use link below<br><a href=\"http://www.lifeincode.net/programming/hadoop-building-the-jar-of-wordcount-in-intellij-idea/\">Building the Jar of wordcount in IntelliJ IDEA</a></p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2b\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            b. Copying Files From Local To HDFS \n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2a\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2c\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "package edu.classes.hdfs;\n",
    "\n",
    "import org.apache.hadoop.io.IOUtils;\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.fs.FileSystem;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "import org.apache.hadoop.util.Progressable;\n",
    "\n",
    "import java.io.BufferedInputStream;\n",
    "import java.io.FileInputStream;\n",
    "import java.io.InputStream;\n",
    "import java.io.OutputStream;\n",
    "import java.net.URI;\n",
    "\n",
    "\n",
    "public class MyFileCopy {\n",
    "\n",
    "    public static void main(String[] args) throws Exception {\n",
    "\n",
    "        String localPath = args[0];\n",
    "        String hdfsPath = args[1];\n",
    "\n",
    "        InputStream in = new BufferedInputStream(new FileInputStream(localPath));\n",
    "\n",
    "        Configuration conf = new Configuration();\n",
    "        conf.setInt(\"dfs.block.size\",16777216); // 16MB\n",
    "\n",
    "        FileSystem fs = FileSystem.get(URI.create(hdfsPath), conf);\n",
    "\n",
    "        // fs.copyFromLocalFile();\n",
    "\n",
    "        OutputStream out = fs.create(new Path(hdfsPath), new Progressable() {\n",
    "            @Override\n",
    "            public void progress() {\n",
    "                System.out.print(\".\");\n",
    "            }\n",
    "        });\n",
    "\n",
    "        IOUtils.copyBytes(in, out, 4096, true);\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2c\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            c. Other manipulations\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2b\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2d\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-info\">\n",
    "  <div class=\"msg-text-info\"><p>For more information use link below<br><a href=\"https://github.com/saagie/example-java-read-and-write-from-hdfs/blob/master/src/main/java/io/saagie/example/hdfs/Main.java\">example-java-read-and-write-from-hdfs</a><br><a href=\"https://tutorials.techmytalk.com/2014/08/16/hadoop-hdfs-java-api/\">Hadoop HDFS JAVA API</a></p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Get/set property values in configuration files</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-info\">\n",
    "  <div class=\"msg-text-info\"><p>The default configurations of a HDFS node see <a href=\"https://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml\">here</a></p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2d\"></a>\n",
    "<div style=\"display:table; width:100%\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-style:italic; font-weight:bold; font-size:12pt\">\n",
    "            d. Running on Cloudera\n",
    "        </div>\n",
    "        <div style=\"display:table-cell; border:1px solid lightgrey; width:20%\">\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center; background-color:whitesmoke;\">\n",
    "                <a href=\"#2a\">Back</a>\n",
    "            </div>\n",
    "            <div style=\"display:table-cell; width:10%; text-align:center;\">\n",
    "                <a href=\"#2c\">Next</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Connect to the local Cloudera VM via SSH and create the <span class=\"code-font\">/home/cloudera/classes/hdfs</span> directory</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Copy data to your local Cloudera VM</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo scp -P 2222 /YOUR_PATH/Input/data.txt cloudera@127.0.0.1:/home/cloudera/classes/hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Copy the jar files</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo scp -P 2222 /YOUR_PATH/out/artifacts/CopyFile_jar/CopyFile.jar cloudera@127.0.0.1:/home/cloudera/classes/hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sudo scp -P 2222 /YOUR_PATH/out/artifacts/HDFSTest2_jar/ReadFile.jar cloudera@127.0.0.1:/home/cloudera/classes/hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Connect to the local Cloudera VM via SSH</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Run the jar file to copy the local data to the HDFS</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoop jar /home/cloudera/classes/hdfs/CopyFile.jar \\\n",
    "            /home/cloudera/classes/hdfs/data.txt \\\n",
    "            hdfs:///hdfs_data/output/data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Verify that the file is in the HDFS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -ls /hdfs_data/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Print out last 1kb of the file</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -tail /hdfs_data/output/data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Run the jar file to read data from HDFS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoop jar /home/cloudera/classes/hdfs/ReadFile.jar \\\n",
    "            hdfs:///hdfs_data/output/data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Delete the output directory</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs dfs -rm -r /hdfs_data/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">3. HDFS on EMR Cluster</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To content</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-task\">\n",
    "  <div class=\"msg-text-task\"><p>Deploy an EMR cluser with 3 instances and run the apps from the previous section</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>1. Check a JDK and Hadoop version on the EMR Master</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>2. Create an IntelliJ Project with an appropriate JDK and Hadoop version</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>3. Create jar files for the ReadFile and CopyFile classes</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>4. Copy jar files to the EMR Master</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>5. Download archive of data using <span class=\"code-font\">wget</span> to a local file system of the EMR Master, and extract data</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Reference to dataset: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"msg-block msg-info\">\n",
    "  <div class=\"msg-text-info\"><p>For more information about this dataset click on the link below<br><a href=\"http://jmcauley.ucsd.edu/data/amazon/\">Amazon product data</a></p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>6. Run the jar file for copying the extracted data to the HDFS</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>7. Check that the file successfully uploaded to the HDFS using shell commands</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>8. Display location of file blocks in the cluster</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">4. References</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To content</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
