{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18pt; padding-top:20px; text-align:center\"><b>Boston House Price and </b> <span style=\"font-weight:bold; color:green\">Spark MLlib</span></div><hr>\n",
    "<div style=\"text-align:right;\">Sergei Papulin <span style=\"font-style: italic;font-weight: bold;\">(papulin_bmstu@mail.ru)</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"0\"></a>\n",
    "<div><span style=\"font-size:14pt; font-weight:bold\">Contents</span>\n",
    "    <ol>\n",
    "        <li><a href=\"#1\">Initial dataset</a></li>\n",
    "        <li><a href=\"#2\">Regression and cross-validation</a></li>\n",
    "        <li><a href=\"#3\">References</a></li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>[OPTIONAL] <b>Environment Setup</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"]=\"/usr/lib/spark\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/opt/anaconda3/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/opt/anaconda3/bin/python\"\n",
    "\n",
    "spark_home = os.environ.get(\"SPARK_HOME\")\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python\"))\n",
    "sys.path.insert(0, os.path.join(spark_home, \"python/lib/py4j-0.10.7-src.zip\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Run Spark</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf() \\\n",
    "        .setAppName(\"bostonApp\") \\\n",
    "        .setMaster(\"yarn\") \\\n",
    "        .set(\"spark.submit.deployMode\", \"client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run **locally**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf() \\\n",
    "        .setAppName(\"bostonApp\") \\\n",
    "        .setMaster(\"local[2]\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Spark Session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"bostonApp\") \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">1. Initial dataset</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To contents</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, DoubleType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>[IF NEEDED] Copy local input dataset to HDFS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal data/price-regression-cv-data/boston-house-price.csv data/spark_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls data/spark_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Define a dataset scheme</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/YOUR_PATH/data/price-regression-cv-data/boston-house-price.csv\"\n",
    "\n",
    "schema_house = StructType(\n",
    "    [StructField(\"CRIM\", DoubleType(), True), # per capita crime rate by town\n",
    "     StructField(\"ZN\", DoubleType(), True), # proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "     StructField(\"INDUS\", DoubleType(), True), # proportion of non-retail business acres per town\n",
    "     StructField(\"CHAS\", DoubleType(), True), # Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "     StructField(\"NOX\", DoubleType(), True), # nitric oxides concentration (parts per 10 million)\n",
    "     StructField(\"RM\", DoubleType(), True), # average number of rooms per dwelling\n",
    "     StructField(\"AGE\", DoubleType(), True), # proportion of owner-occupied units built prior to 1940\n",
    "     StructField(\"DIS\", DoubleType(), True), # weighted distances to five Boston employment centres\n",
    "     StructField(\"RAD\", DoubleType(), True), # index of accessibility to radial highways\n",
    "     StructField(\"TAX\", DoubleType(), True), # full-value property-tax rate per $10,000\n",
    "     StructField(\"PTRATIO\", DoubleType(), True), # pupil-teacher ratio by town\n",
    "     StructField(\"B\", DoubleType(), True), # 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "     StructField(\"LSTAT\", DoubleType(), True), # % lower status of the population\n",
    "     StructField(\"MEDV\", DoubleType(), True)]) # Median value of owner-occupied homes in $1000’s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create a Spark dataframe</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house = spark.read.load(path=dataset_path,\n",
    "                           format=\"csv\", \n",
    "                           schema=schema_house,\n",
    "                           header=\"false\", \n",
    "                           inferSchema=\"false\", \n",
    "                           sep=\",\")\n",
    "df_house.persist()\n",
    "df_house.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Display the number of rows</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Calculate data statistics</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house_stats = df_house.describe()\n",
    "df_house_stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Display formatted output using Pandas</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house_stats.toPandas().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Draw plots for initial dataset</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Sample data from Spark dataframe</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df_house_sample = df_house.sample(False, 0.2, seed=123).toPandas()\n",
    "pd_df_house_sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Draw plots</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(pd_df_house_sample, figsize=(15, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2, figsize=[10,10])\n",
    "plt.matshow(pd_df_house_sample.corr(), vmin=-1, vmax=1, fignum=2)\n",
    "plt.title(\"Correlation\")\n",
    "plt.xticks(range(len(pd_df_house_sample.columns)), pd_df_house_sample.columns)\n",
    "plt.yticks(range(len(pd_df_house_sample.columns)), pd_df_house_sample.columns)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">2. Regression and cross-validation</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To contents</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\"RM\", \"LSTAT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_assembler = VectorAssembler(inputCols=feature_columns,\n",
    "                                    outputCol=\"Features\")\n",
    "\n",
    "df_house_with_features = feature_assembler.transform(df_house)\n",
    "df_house_with_features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_house_with_features.select(\"Features\", \"MEDV\")\n",
    "df_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Split the data into training and test subsets</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df_features.randomSplit([0.8, 0.2], seed=123)\n",
    "df_train.count(), df_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Initialize a linear model</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>solver = {\"l-bfgs\", \"normal\", \"auto\"}</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lr = LinearRegression(maxIter=100, solver=\"l-bfgs\", featuresCol=\"Features\", labelCol=\"MEDV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Cross-Validation</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>metric = {\"rmse\", \"mse\", \"r2\", \"mae\"}</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", predictionCol=\"prediction\", labelCol=\"MEDV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create a grid of hyperparameters</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParamGridBuilder()\\\n",
    "          .addGrid(reg_lr.regParam, [0.1, 0.01]) \\\n",
    "          .addGrid(reg_lr.fitIntercept, [False, True]) \\\n",
    "          .addGrid(reg_lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "          .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Initialize a cross-validator</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=reg_lr, numFolds=4, estimatorParamMaps=grid, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Model selection</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Run cross-validation (train the models)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cv = cv.fit(df_train)\n",
    "m_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Display a list of output metrics for all combinations of hyperparameters</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cv.avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Display a list of model hyperparameters that were used </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cv.extractParamMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Get the best model</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_m_lr = m_cv.bestModel\n",
    "best_m_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Display the best model coefficients</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_m_lr.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_m_lr.intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The bes model interpretation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pred = lambda x1, x2: best_m_lr.intercept + best_m_lr.coefficients[0] * x1 + best_m_lr.coefficients[1] * x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pred(6, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Training summary</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_m_lr.summary.objectiveHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_m_lr.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_m_lr.summary.totalIterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Test the best model</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred = m_cv.transform(df_test)\n",
    "df_test_pred.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Set R^2 metric</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.setParams(metricName=\"r2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Result</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(df_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Get a sample to draw plots</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df_house_sample = df_house.select(\"RM\", \"LSTAT\", \"MEDV\").sample(False, 0.2, seed=123).toPandas()\n",
    "pd_df_house_sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Draw plots with initial and predicted values</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2, figsize=[10,5])\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "plt.plot(pd_df_house_sample[\"RM\"], \n",
    "         pd_df_house_sample[\"MEDV\"], \n",
    "         \"bo\",\n",
    "         label=\"initial\")\n",
    "plt.plot(pd_df_house_sample[\"RM\"], \n",
    "         f_pred(pd_df_house_sample[\"RM\"], pd_df_house_sample[\"LSTAT\"]), \n",
    "         \"ro\", \n",
    "         label=\"predicted\")\n",
    "plt.axis([3, 10, 0, 55])\n",
    "plt.title(\"RM-MEDV\")\n",
    "plt.xlabel(\"RM\")\n",
    "plt.ylabel(\"MEDV, $1000’s\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.plot(pd_df_house_sample[\"LSTAT\"], \n",
    "         pd_df_house_sample[\"MEDV\"], \n",
    "         \"bo\",\n",
    "         label=\"initial\")\n",
    "plt.plot(pd_df_house_sample[\"LSTAT\"], \n",
    "         f_pred(pd_df_house_sample[\"RM\"], pd_df_house_sample[\"LSTAT\"]), \n",
    "         \"ro\", \n",
    "         label=\"predicted\")\n",
    "plt.axis([3, 10, 0, 55])\n",
    "plt.title(\"LSTAT-MEDV\")\n",
    "plt.xlabel(\"LSTAT\")\n",
    "plt.ylabel(\"MEDV, $1000’s\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Stop Spark Context</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "<div style=\"display:table; width:100%; padding-top:10px; padding-bottom:10px; border-bottom:1px solid lightgrey\">\n",
    "    <div style=\"display:table-row\">\n",
    "        <div style=\"display:table-cell; width:80%; font-size:14pt; font-weight:bold\">3. References</div>\n",
    "    \t<div style=\"display:table-cell; width:20%; text-align:center; background-color:whitesmoke; border:1px solid lightgrey\"><a href=\"#0\">To contents</a></div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "linreg",
  "notebookId": 3925429819234013
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
